{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to Data Wizardry with Python","text":"<p>Welcome to your comprehensive guide for transitioning from R and SPSS to Python!</p>"},{"location":"#about-this-project","title":"About This Project","text":"<p>Data Wizardry with Python is an internal training repository designed to help analysts and data scientists make the transition to Python. Whether you're coming from R, SPSS, or are completely new to programming for analytics, this resource will guide you through the essentials.</p>"},{"location":"#why-python-for-analytics","title":"Why Python for Analytics?","text":"<p>Python has become one of the most popular languages for data analysis because:</p> <ul> <li>Versatile: Use the same language for data cleaning, analysis, visualization, and deployment</li> <li>Powerful Libraries: pandas, NumPy, matplotlib, seaborn, and more provide comprehensive functionality</li> <li>Active Community: Extensive documentation, tutorials, and support</li> <li>Integration: Works seamlessly with databases, APIs, and web frameworks</li> <li>Free and Open Source: No licensing costs, transparent development</li> </ul>"},{"location":"#what-youll-learn","title":"What You'll Learn","text":""},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Installation Overview: Setup requirements and workflow</li> <li>Installing Python: Get Python from Company Portal</li> <li>Using uv: Modern package management with uv sync</li> <li>Running Notebooks: Work with Jupyter in VS Code</li> <li>Quickstart: Your first data analysis</li> </ul>"},{"location":"#core-guides","title":"Core Guides","text":"<ul> <li>Python Basics for Analysts: Essential Python concepts</li> <li>R to Python Guide: Translation guide for R users</li> <li>SPSS to Python Guide: Translation guide for SPSS users</li> </ul>"},{"location":"#pandas-documentation","title":"pandas Documentation","text":"<ul> <li>pandas Overview: Comprehensive pandas guide</li> <li>pandas Cheat Sheet: Quick reference for common tasks</li> </ul>"},{"location":"#interactive-notebooks","title":"Interactive Notebooks","text":"<p>Hands-on tutorials in <code>notebooks/</code>:</p> <ol> <li>Introduction &amp; Data Loading (<code>01_into_and_data_loading.ipynb</code>): Read CSV files, inspect DataFrames, understand data types</li> <li>Selection &amp; Indexing (<code>02_selection_and_indexing.ipynb</code>): Access and filter data efficiently</li> <li>Cleaning &amp; Transformations (<code>03_cleaning_and_transformations.ipynb</code>): Handle missing values, duplicates, and data quality</li> <li>Merging &amp; Joining (<code>04_merging_and_joining.ipynb</code>): Combine datasets from multiple sources</li> <li>GroupBy &amp; Aggregation (<code>05_groupby_and_aggregation.ipynb</code>): Grouping, summarizing, and aggregation</li> <li>Reshaping &amp; Pivoting (<code>06_reshaping_and_pivoting.ipynb</code>): Reshape data between long and wide formats</li> <li>Exporting &amp; Saving (<code>07_exporting_and_saving.ipynb</code>): Save results to various formats</li> </ol>"},{"location":"#reference","title":"Reference","text":"<ul> <li>Cheatsheets: Quick references for NumPy, Matplotlib, and more</li> <li>Glossary: Key terms and concepts</li> <li>Resources: External learning materials</li> </ul>"},{"location":"#repository-structure","title":"Repository Structure","text":"<pre><code>Data-Wizardry-with-Python/\n\u251c\u2500\u2500 notebooks/          # Jupyter notebooks with hands-on tutorials\n\u2502   \u251c\u2500\u2500 01_into_and_data_loading.ipynb\n\u2502   \u251c\u2500\u2500 02_selection_and_indexing.ipynb\n\u2502   \u251c\u2500\u2500 03_cleaning_and_transformations.ipynb\n\u2502   \u251c\u2500\u2500 04_merging_and_joining.ipynb\n\u2502   \u251c\u2500\u2500 05_groupby_and_aggregation.ipynb\n\u2502   \u251c\u2500\u2500 06_reshaping_and_pivoting.ipynb\n\u2502   \u2514\u2500\u2500 07_exporting_and_saving.ipynb\n\u251c\u2500\u2500 data/              # Sample datasets\n\u2502   \u251c\u2500\u2500 media_contacts.csv\n\u2502   \u2514\u2500\u2500 socio_demos.csv\n\u251c\u2500\u2500 docs/              # MkDocs documentation source\n\u2502   \u251c\u2500\u2500 getting-started/\n\u2502   \u251c\u2500\u2500 guides/\n\u2502   \u251c\u2500\u2500 cheatsheets/\n\u2502   \u2514\u2500\u2500 reference/\n\u251c\u2500\u2500 pyproject.toml     # Modern Python project configuration\n\u2514\u2500\u2500 mkdocs.yml         # Documentation configuration\n</code></pre>"},{"location":"#learning-approach","title":"Learning Approach","text":"<p>This training follows a learn-by-doing philosophy:</p> <ol> <li>Read: Documentation explains concepts clearly</li> <li>Code: Jupyter notebooks let you practice interactively</li> <li>Experiment: Modify examples to deepen understanding</li> <li>Apply: Use what you've learned on real data</li> </ol>"},{"location":"#prerequisites","title":"Prerequisites","text":"<ul> <li>Basic understanding of data analysis concepts</li> <li>Familiarity with spreadsheets or statistical software</li> <li>Willingness to learn and experiment!</li> </ul> <p>No prior Python experience is required, but it's helpful if you've programmed before in any language.</p>"},{"location":"#support-and-community","title":"Support and Community","text":"<ul> <li>\ud83d\udcd6 Browse the full documentation using the navigation menu</li> <li>\ud83d\udcbb Work through the Jupyter notebooks in the <code>notebooks/</code> directory</li> <li>\ud83d\udd0d Search for specific topics using the search bar</li> <li>\ud83d\udcdd Check the Glossary for terminology</li> <li>\ud83d\udcca Use our Cheatsheets for quick reference</li> </ul> <p>Ready to begin your Python journey? Let's get started!</p> <p>Get Started \u2192</p>"},{"location":"cheatsheets/cheatsheets/","title":"Cheat Sheets","text":"<p>Quick reference guides for common Python data analysis operations.</p>"},{"location":"cheatsheets/cheatsheets/#core-libraries","title":"Core Libraries","text":""},{"location":"cheatsheets/cheatsheets/#pandas","title":"pandas","text":"<p>For comprehensive pandas reference, see our dedicated pandas guides:</p> <ul> <li>pandas Overview - Complete guide to pandas</li> <li>pandas Cheat Sheet - Quick reference</li> </ul>"},{"location":"cheatsheets/cheatsheets/#python-basics","title":"Python Basics","text":""},{"location":"cheatsheets/cheatsheets/#common-data-types","title":"Common Data Types","text":"<pre><code>42              # int\n3.14            # float\n\"text\"          # str\nTrue/False      # bool\n[1, 2, 3]       # list (mutable)\n(1, 2, 3)       # tuple (immutable)\n{'a': 1, 'b': 2}  # dict\n{1, 2, 3}       # set\n</code></pre>"},{"location":"cheatsheets/cheatsheets/#control-structures","title":"Control Structures","text":"<pre><code># Conditional\nif condition:\n    # do something\nelif other_condition:\n    # do something else\nelse:\n    # default\n\n# For loop\nfor item in items:\n    print(item)\n\n# While loop\nwhile condition:\n    # repeat\n\n# List comprehension\nsquares = [x**2 for x in range(10)]\nevens = [x for x in range(10) if x % 2 == 0]\n\n# Dict comprehension\n{k: v**2 for k, v in dict.items()}\n</code></pre>"},{"location":"cheatsheets/cheatsheets/#function-definitions","title":"Function Definitions","text":"<pre><code>def function_name(param1, param2='default'):\n    \"\"\"Docstring describing the function.\"\"\"\n    result = param1 + param2\n    return result\n\n# Lambda (anonymous function)\nsquare = lambda x: x**2\n\n# Multiple return values\ndef min_max(numbers):\n    return min(numbers), max(numbers)\n</code></pre>"},{"location":"cheatsheets/cheatsheets/#string-operations","title":"String Operations","text":"<pre><code># Formatting (use f-strings in modern Python)\nname, age = \"Alice\", 25\nf\"Hello, {name}! You are {age} years old.\"\nf\"Result: {value:.2f}\"  # Format with 2 decimals\n\n# Common methods\ntext.lower()            # Lowercase\ntext.upper()            # Uppercase\ntext.strip()            # Remove whitespace\ntext.replace('old', 'new')\ntext.split(',')         # Split into list\n','.join(items)         # Join list into string\n'substring' in text     # Check contains\n</code></pre>"},{"location":"cheatsheets/cheatsheets/#matplotlib","title":"matplotlib","text":""},{"location":"cheatsheets/cheatsheets/#basic-plotting","title":"Basic Plotting","text":"<pre><code>import matplotlib.pyplot as plt\n\n# Line plot\nplt.plot(x, y)\nplt.plot(x, y, label='Series 1', color='blue', linestyle='--')\n\n# Customize\nplt.xlabel('X Label')\nplt.ylabel('Y Label')\nplt.title('Title')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n# Save figure\nplt.savefig('plot.png', dpi=300, bbox_inches='tight')\n</code></pre>"},{"location":"cheatsheets/cheatsheets/#common-plot-types","title":"Common Plot Types","text":"<pre><code>plt.scatter(x, y)               # Scatter plot\nplt.bar(categories, values)     # Bar chart\nplt.barh(categories, values)    # Horizontal bar chart\nplt.hist(data, bins=20)         # Histogram\nplt.boxplot(data)               # Box plot\nplt.pie(sizes, labels=labels)   # Pie chart\n\n# Subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\nax1.plot(x, y1)\nax2.scatter(x, y2)\n</code></pre>"},{"location":"cheatsheets/cheatsheets/#seaborn","title":"seaborn","text":""},{"location":"cheatsheets/cheatsheets/#statistical-plotting","title":"Statistical Plotting","text":"<pre><code>import seaborn as sns\n\n# Set style\nsns.set_theme(style='whitegrid')\nsns.set_palette('husl')\n\n# Distribution plots\nsns.histplot(data=df, x='value', bins=20)\nsns.kdeplot(data=df, x='value')\nsns.boxplot(data=df, x='category', y='value')\nsns.violinplot(data=df, x='category', y='value')\n\n# Relationship plots\nsns.scatterplot(data=df, x='x', y='y', hue='category')\nsns.lineplot(data=df, x='time', y='value', hue='group')\nsns.regplot(data=df, x='x', y='y')  # With regression line\n\n# Categorical plots\nsns.barplot(data=df, x='category', y='value')\nsns.countplot(data=df, x='category')\n\n# Matrix plots\nsns.heatmap(df.corr(), annot=True, cmap='coolwarm')\nsns.clustermap(df, cmap='viridis')\n</code></pre>"},{"location":"cheatsheets/cheatsheets/#numpy","title":"NumPy","text":""},{"location":"cheatsheets/cheatsheets/#array-creation","title":"Array Creation","text":"<pre><code>import numpy as np\n\n# From Python objects\nnp.array([1, 2, 3])\nnp.array([[1, 2], [3, 4]])\n\n# Initialized arrays\nnp.zeros(5)                  # All zeros\nnp.ones((3, 3))              # All ones\nnp.full((2, 2), 7)           # All 7s\nnp.eye(3)                    # Identity matrix\n\n# Ranges\nnp.arange(0, 10, 2)          # [0, 2, 4, 6, 8]\nnp.linspace(0, 1, 5)         # 5 values from 0 to 1\n\n# Random\nnp.random.rand(3, 3)         # Uniform [0, 1)\nnp.random.randn(3, 3)        # Standard normal\nnp.random.randint(0, 10, 5)  # Random integers\n</code></pre>"},{"location":"cheatsheets/cheatsheets/#array-operations","title":"Array Operations","text":"<pre><code># Math operations (element-wise)\narr + 5\narr * 2\narr ** 2\nnp.sqrt(arr)\nnp.exp(arr)\nnp.log(arr)\n\n# Aggregations\narr.mean()\narr.std()\narr.min()\narr.max()\narr.sum()\narr.cumsum()\n\n# Axis operations\narr.mean(axis=0)  # Column means\narr.sum(axis=1)   # Row sums\n\n# Reshaping\narr.reshape(3, 4)\narr.flatten()\narr.T  # Transpose\n</code></pre>"},{"location":"cheatsheets/cheatsheets/#scipystats","title":"scipy.stats","text":""},{"location":"cheatsheets/cheatsheets/#statistical-tests","title":"Statistical Tests","text":"<pre><code>from scipy import stats\n\n# T-tests\nstats.ttest_1samp(data, popmean=0)           # One-sample\nstats.ttest_ind(group1, group2)               # Independent samples\nstats.ttest_rel(before, after)                # Paired samples\n\n# Correlation\nstats.pearsonr(x, y)                          # Pearson correlation\nstats.spearmanr(x, y)                         # Spearman correlation\n\n# ANOVA\nstats.f_oneway(group1, group2, group3)        # One-way ANOVA\n\n# Chi-square\nstats.chi2_contingency(crosstab)              # Chi-square test\n\n# Normality tests\nstats.shapiro(data)                           # Shapiro-Wilk test\nstats.normaltest(data)                        # D'Agostino-Pearson test\n\n# Non-parametric\nstats.mannwhitneyu(group1, group2)            # Mann-Whitney U\nstats.wilcoxon(before, after)                 # Wilcoxon signed-rank\nstats.kruskal(group1, group2, group3)         # Kruskal-Wallis\n</code></pre>"},{"location":"cheatsheets/cheatsheets/#distributions","title":"Distributions","text":"<pre><code># Normal distribution\nstats.norm.pdf(x, loc=0, scale=1)             # Probability density\nstats.norm.cdf(x, loc=0, scale=1)             # Cumulative distribution\nstats.norm.ppf(0.95, loc=0, scale=1)          # Quantile (inverse CDF)\nstats.norm.rvs(loc=0, scale=1, size=100)      # Random samples\n</code></pre>"},{"location":"cheatsheets/cheatsheets/#jupyter-keyboard-shortcuts","title":"Jupyter Keyboard Shortcuts","text":""},{"location":"cheatsheets/cheatsheets/#command-mode-press-esc-to-enter","title":"Command Mode (press Esc to enter)","text":"Shortcut Action <code>A</code> Insert cell above <code>B</code> Insert cell below <code>DD</code> Delete cell <code>M</code> Convert to Markdown <code>Y</code> Convert to Code <code>Z</code> Undo delete cell <code>Shift+J</code> Select cells below <code>Shift+K</code> Select cells above <code>Shift+M</code> Merge selected cells"},{"location":"cheatsheets/cheatsheets/#edit-mode-press-enter-to-enter","title":"Edit Mode (press Enter to enter)","text":"Shortcut Action <code>Shift+Enter</code> Run cell, select below <code>Ctrl+Enter</code> Run cell <code>Alt+Enter</code> Run cell, insert below <code>Ctrl+/</code> Comment/uncomment <code>Tab</code> Indent or autocomplete <code>Shift+Tab</code> Show function tooltip <code>Ctrl+]</code> Indent <code>Ctrl+[</code> Dedent"},{"location":"cheatsheets/cheatsheets/#common-workflows","title":"Common Workflows","text":""},{"location":"cheatsheets/cheatsheets/#data-loading-pipeline","title":"Data Loading Pipeline","text":"<pre><code>import pandas as pd\nimport numpy as np\n\n# Load data\ndf = pd.read_csv('data.csv')\n\n# Initial inspection\nprint(df.shape)\nprint(df.head())\nprint(df.info())\n\n# Check missing values\nprint(df.isnull().sum())\n\n# Summary statistics\nprint(df.describe())\n</code></pre>"},{"location":"cheatsheets/cheatsheets/#data-cleaning-pipeline","title":"Data Cleaning Pipeline","text":"<pre><code># Remove duplicates\ndf = df.drop_duplicates()\n\n# Handle missing values\ndf = df.dropna(subset=['important_col'])\ndf['col'].fillna(df['col'].mean(), inplace=True)\n\n# Fix data types\ndf['date'] = pd.to_datetime(df['date'])\ndf['category'] = df['category'].astype('category')\n\n# Remove outliers (example: remove values &gt; 3 std dev)\ndf = df[np.abs(df['value'] - df['value'].mean()) &lt;= (3 * df['value'].std())]\n</code></pre>"},{"location":"cheatsheets/cheatsheets/#analysis-and-visualization","title":"Analysis and Visualization","text":"<pre><code>import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Group and aggregate\nsummary = df.groupby('category')['value'].agg(['mean', 'count', 'std'])\n\n# Visualize\nsns.barplot(data=df, x='category', y='value')\nplt.title('Average Value by Category')\nplt.tight_layout()\nplt.show()\n\n# Export results\nsummary.to_csv('summary.csv')\n</code></pre>"},{"location":"cheatsheets/cheatsheets/#external-resources","title":"External Resources","text":""},{"location":"cheatsheets/cheatsheets/#official-documentation","title":"Official Documentation","text":"<ul> <li>pandas: pandas.pydata.org/docs</li> <li>NumPy: numpy.org/doc</li> <li>Matplotlib: matplotlib.org</li> <li>seaborn: seaborn.pydata.org</li> <li>SciPy: docs.scipy.org</li> </ul>"},{"location":"cheatsheets/cheatsheets/#downloadable-cheat-sheets","title":"Downloadable Cheat Sheets","text":"<ul> <li>pandas Official Cheat Sheet (PDF)</li> <li>NumPy Cheat Sheet</li> <li>Matplotlib Cheat Sheets</li> <li>seaborn Tutorial</li> </ul>"},{"location":"cheatsheets/cheatsheets/#quick-tutorials","title":"Quick Tutorials","text":"<ul> <li>pandas: 10 Minutes to pandas</li> <li>NumPy: NumPy Quickstart</li> <li>Matplotlib: pyplot Tutorial</li> </ul>"},{"location":"getting-started/01-installation/","title":"Installation Guide","text":"<p>Get up and running with Python for data analytics. This guide provides an overview of the installation process.</p>"},{"location":"getting-started/01-installation/#quick-start-path","title":"Quick Start Path","text":"<p>Follow these guides in order:</p> <ol> <li>Installing Python - Get Python and Git via Company Portal</li> <li>Using uv - Set up our recommended package manager</li> <li>Running Notebooks - Configure VS Code for Jupyter notebooks</li> <li>Quick Start - Your first data analysis</li> </ol>"},{"location":"getting-started/01-installation/#what-youll-install","title":"What You'll Install","text":""},{"location":"getting-started/01-installation/#core-requirements","title":"Core Requirements","text":"<ul> <li>Python 3.11+: Programming language for data analysis</li> <li>Git: Version control system</li> <li>uv: Fast, modern Python package manager</li> <li>VS Code: Code editor with excellent Jupyter support</li> </ul>"},{"location":"getting-started/01-installation/#python-packages","title":"Python Packages","text":"<p>These are installed automatically via <code>requirements.txt</code>:</p> <ul> <li>pandas: Data manipulation and analysis</li> <li>numpy: Numerical computing</li> <li>matplotlib &amp; seaborn: Data visualization</li> <li>jupyter: Interactive notebooks</li> <li>scipy &amp; statsmodels: Statistical analysis</li> <li>openpyxl: Excel file support</li> <li>pyreadstat: SPSS file reading</li> </ul>"},{"location":"getting-started/01-installation/#installation-steps","title":"Installation Steps","text":""},{"location":"getting-started/01-installation/#1-install-python-git","title":"1. Install Python &amp; Git","text":"<p>Use Company Portal (recommended) or manual installation.</p> <p>\u2192 See Installing Python for details</p>"},{"location":"getting-started/01-installation/#2-install-uv-package-manager","title":"2. Install uv Package Manager","text":"<p>Install uv with pip:</p> <pre><code>pip install uv\n</code></pre> <p>\u2192 See Using uv for details</p>"},{"location":"getting-started/01-installation/#3-clone-the-repository","title":"3. Clone the Repository","text":"<pre><code>git clone https://gitlab.com/your-org/Data-Wizardry-with-Python.git\ncd Data-Wizardry-with-Python\n</code></pre>"},{"location":"getting-started/01-installation/#4-sync-dependencies","title":"4. Sync Dependencies","text":"<p>Use the modern <code>uv sync</code> workflow:</p> <pre><code># Install all dependencies from pyproject.toml\nuv sync --all-groups\n</code></pre> <p>This creates the virtual environment and installs all packages in one command.</p>"},{"location":"getting-started/01-installation/#5-configure-vs-code","title":"5. Configure VS Code","text":"<p>Install VS Code and the Python, Jupyter, and Pylance extensions.</p> <p>\u2192 See Running Notebooks for details</p>"},{"location":"getting-started/01-installation/#verification","title":"Verification","text":"<p>Test your setup:</p> <pre><code># Activate environment\n.venv\\Scripts\\activate  # Windows\nsource .venv/bin/activate  # macOS/Linux\n\n# Test imports\npython -c \"import pandas, numpy, matplotlib, jupyter; print('\u2713 All packages installed successfully!')\"\n</code></pre>"},{"location":"getting-started/01-installation/#common-issues","title":"Common Issues","text":""},{"location":"getting-started/01-installation/#command-not-found-errors","title":"\"Command not found\" errors","text":"<ul> <li>Ensure Python and Git are in your PATH</li> <li>Restart your terminal after installation</li> <li>See Installing Python troubleshooting section</li> </ul>"},{"location":"getting-started/01-installation/#sync-fails","title":"Sync fails","text":"<ul> <li>Update uv: <code>pip install --upgrade uv</code></li> <li>Check internet connection</li> <li>See Using uv troubleshooting section</li> </ul>"},{"location":"getting-started/01-installation/#jupyter-kernel-wont-start-in-vs-code","title":"Jupyter kernel won't start in VS Code","text":"<ul> <li>Verify correct interpreter is selected</li> <li>Restart VS Code</li> <li>See Running Notebooks troubleshooting section</li> </ul>"},{"location":"getting-started/01-installation/#whats-next","title":"What's Next?","text":"<p>Once installation is complete:</p> <ol> <li>Learn the basics: Try the Quick Start Guide</li> <li>Open a notebook: Navigate to <code>notebooks/01_into_and_data_loading.ipynb</code></li> <li>Coming from R?: Check the R to Python Guide</li> <li>Coming from SPSS?: Check the SPSS to Python Guide</li> </ol>"},{"location":"getting-started/01-installation/#getting-help","title":"Getting Help","text":"<p>If you run into issues:</p> <ul> <li>Check the detailed guides linked above</li> <li>Review the Git Guide for Git-specific questions</li> <li>Consult the Glossary for terminology</li> <li>Ask a colleague who's already set up</li> </ul>"},{"location":"getting-started/02-python/","title":"Installing Python","text":"<p>This guide covers installing Python and Git for your analytics work.</p>"},{"location":"getting-started/02-python/#prerequisites-via-company-portal","title":"Prerequisites via Company Portal","text":"<p>The recommended way to install Python and Git is through the Company Portal:</p> <ol> <li>Open Company Portal on your machine</li> <li>Search for and install:</li> <li>Python 3.11 (or latest version available)</li> <li>Git for Windows (Windows) or Git (macOS/Linux)</li> <li>Verify installations by opening a terminal and running:</li> </ol> <pre><code>python --version\ngit --version\n</code></pre> <p>You should see version numbers for both tools.</p>"},{"location":"getting-started/02-python/#alternative-manual-installation","title":"Alternative: Manual Installation","text":"<p>If Company Portal isn't available or doesn't have the version you need:</p>"},{"location":"getting-started/02-python/#python","title":"Python","text":"<p>Download and Install:</p> <ol> <li>Go to python.org/downloads</li> <li>Download Python 3.11 or later</li> <li>Run the installer</li> <li>\u2705 Important (Windows): Check \"Add Python to PATH\"</li> <li>Verify installation:</li> </ol> <pre><code>python --version\n</code></pre>"},{"location":"getting-started/02-python/#git","title":"Git","text":"<p>Download and Install:</p> <ol> <li>Go to git-scm.com</li> <li>Download for your operating system</li> <li>Run the installer (accept defaults)</li> <li>Verify installation:</li> </ol> <pre><code>git --version\n</code></pre> <p>For detailed Git setup and usage, see the Git Guide.</p>"},{"location":"getting-started/02-python/#what-about-anaconda","title":"What About Anaconda?","text":"<p>While Anaconda is a popular Python distribution that includes many data science packages pre-installed, we recommend using standard Python with uv for this team. This approach is:</p> <ul> <li>Lighter weight: Smaller download and disk space</li> <li>Faster: uv is significantly faster than conda</li> <li>More flexible: Better control over dependencies</li> <li>Industry standard: More similar to typical Python workflows</li> </ul> <p>If you already have Anaconda installed, you can still use it, but the rest of this guide assumes standard Python + uv.</p>"},{"location":"getting-started/02-python/#next-steps","title":"Next Steps","text":"<p>Once Python and Git are installed:</p> <ol> <li>Set up uv: Continue to Using uv</li> <li>Clone the repository: See the Git Guide</li> <li>Configure VS Code: See Running Notebooks</li> </ol>"},{"location":"getting-started/03-uv/","title":"Using uv for Package Management","text":"<p>uv is our recommended Python package manager. It's a modern, extremely fast tool written in Rust that handles dependency management and virtual environments seamlessly.</p>"},{"location":"getting-started/03-uv/#why-uv","title":"Why uv?","text":"<ul> <li>Speed: 10-100x faster than pip</li> <li>Simplicity: Modern workflow with <code>uv sync</code></li> <li>Reliability: Better dependency resolution with lock files</li> <li>Reproducibility: Guaranteed identical environments across team</li> </ul>"},{"location":"getting-started/03-uv/#installing-uv","title":"Installing uv","text":""},{"location":"getting-started/03-uv/#recommended-install-with-pip","title":"Recommended: Install with pip","text":"<p>The simplest and most reliable method:</p> <pre><code>pip install uv\n</code></pre> <p>Verify installation:</p> <pre><code>uv --version\n</code></pre>"},{"location":"getting-started/03-uv/#alternative-standalone-installer","title":"Alternative: Standalone Installer","text":"<p>Windows (PowerShell):</p> <pre><code>powershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n</code></pre> <p>macOS/Linux:</p> <pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre>"},{"location":"getting-started/03-uv/#setting-up-your-project","title":"Setting Up Your Project","text":""},{"location":"getting-started/03-uv/#1-clone-the-repository","title":"1. Clone the Repository","text":"<p>First, get the project code:</p> <pre><code>git clone https://gitlab.td.gfk.com/mm/pet/analysis/data-wizardry-with-python.git\ncd data-wizardry-with-python\n</code></pre>"},{"location":"getting-started/03-uv/#2-sync-dependencies-recommended-workflow","title":"2. Sync Dependencies (Recommended Workflow)","text":"<p>The modern approach using <code>uv sync</code>:</p> <pre><code># Create venv and install all dependencies from pyproject.toml\nuv sync\n\n# Or sync with specific groups\nuv sync --group dev\nuv sync --group docs\nuv sync --all-groups  # Install everything\n</code></pre> <p>This command:</p> <ul> <li>Creates a <code>.venv</code> folder automatically if it doesn't exist</li> <li>Installs all dependencies from <code>pyproject.toml</code></li> <li>Generates/updates <code>uv.lock</code> for reproducibility</li> <li>Ensures everyone has identical package versions</li> </ul>"},{"location":"getting-started/03-uv/#3-activate-the-environment","title":"3. Activate the Environment","text":"<p>Windows (PowerShell):</p> <pre><code>.venv\\Scripts\\activate\n</code></pre> <p>macOS/Linux:</p> <pre><code>source .venv/bin/activate\n</code></pre> <p>You'll see <code>(.venv)</code> in your terminal prompt when activated.</p>"},{"location":"getting-started/03-uv/#understanding-the-workflow","title":"Understanding the Workflow","text":""},{"location":"getting-started/03-uv/#pyprojecttoml-the-source-of-truth","title":"pyproject.toml - The Source of Truth","text":"<p>All dependencies are defined in <code>pyproject.toml</code>:</p> <pre><code>[project]\ndependencies = [\n    \"pandas&gt;=2.0.0\",\n    \"numpy&gt;=1.24.0\",\n    # ... more packages\n]\n\n[dependency-groups]\ndev = [\"pytest&gt;=8.3.0\", \"black&gt;=24.0.0\", ...]\ndocs = [\"mkdocs&gt;=1.5.0\", ...]\nds = [\"scikit-learn&gt;=1.3.0\", ...]\n</code></pre>"},{"location":"getting-started/03-uv/#uvlock-reproducibility","title":"uv.lock - Reproducibility","text":"<p>When you run <code>uv sync</code>, uv creates/updates <code>uv.lock</code> with exact versions:</p> <pre><code># Everyone on the team runs this\nuv sync\n\n# Result: Identical package versions for everyone\n</code></pre> <p>Commit both files to Git:</p> <ul> <li><code>pyproject.toml</code> - What you want</li> <li><code>uv.lock</code> - Exact versions that work</li> </ul>"},{"location":"getting-started/03-uv/#daily-workflow","title":"Daily Workflow","text":""},{"location":"getting-started/03-uv/#with-activated-environment","title":"With Activated Environment","text":"<p>Once you've activated the environment (as shown above), you can run commands normally:</p> <pre><code># Run Python scripts\npython script.py\n\n# Start Jupyter\njupyter lab\n\n# Install new packages with uv add\nuv add package-name\n</code></pre>"},{"location":"getting-started/03-uv/#without-activating-uv-run","title":"Without Activating (uv run)","text":"<p>uv can run commands without activating the environment:</p> <pre><code># Run Python\nuv run python script.py\n\n# Start Jupyter\nuv run jupyter lab\n\n# Run any command in the virtual environment\nuv run &lt;command&gt;\n</code></pre>"},{"location":"getting-started/03-uv/#common-commands","title":"Common Commands","text":""},{"location":"getting-started/03-uv/#working-with-packages","title":"Working with Packages","text":"<pre><code># Sync to latest from pyproject.toml\nuv sync\n\n# Add a new package\nuv add pandas matplotlib\n\n# Add a development dependency\nuv add --group dev pytest\n\n# Remove a package\nuv remove package-name\n\n# Update all packages\nuv sync --upgrade\n\n# Run a command without activating\nuv run python script.py\nuv run jupyter lab\n</code></pre>"},{"location":"getting-started/03-uv/#managing-dependency-groups","title":"Managing Dependency Groups","text":"<pre><code># Sync only core dependencies\nuv sync\n\n# Add dev tools\nuv sync --group dev\n\n# Add docs tools\nuv sync --group docs\n\n# Add everything\nuv sync --all-groups\n</code></pre>"},{"location":"getting-started/03-uv/#python-version-management","title":"Python Version Management","text":"<pre><code># Install Python 3.11\nuv python install 3.11\n\n# Install Python 3.12\nuv python install 3.12\n\n# List installed versions\nuv python list\n\n# Create venv with specific Python\nuv venv --python 3.11\n</code></pre>"},{"location":"getting-started/03-uv/#alternative-using-uv-pip-less-common","title":"Alternative: Using uv pip (Less Common)","text":"<p>You can still use <code>uv pip</code> for traditional workflows:</p> <pre><code># Install from requirements file\nuv pip install -r requirements.txt\n\n# Install specific package\nuv pip install pandas\n\n# List installed packages\nuv pip list\n\n# Freeze environment\nuv pip freeze &gt; requirements.txt\n</code></pre> <p>Note: <code>uv sync</code> is preferred as it ensures reproducibility through lock files.</p>"},{"location":"getting-started/03-uv/#resetting-your-environment","title":"Resetting Your Environment","text":"<p>Sometimes you need a fresh start:</p>"},{"location":"getting-started/03-uv/#quick-reset","title":"Quick Reset","text":"<pre><code># Remove and recreate environment\nRemove-Item -Recurse -Force .venv  # Windows\nrm -rf .venv  # macOS/Linux\n\n# Sync from scratch\nuv sync --all-groups\n</code></pre>"},{"location":"getting-started/03-uv/#clean-cache","title":"Clean Cache","text":"<pre><code># Clear uv's cache (troubleshooting)\nuv cache clean\n</code></pre>"},{"location":"getting-started/03-uv/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/03-uv/#uv-command-not-found","title":"\"uv: command not found\"","text":"<p>After <code>pip install uv</code>, restart your terminal or run:</p> <p>Windows:</p> <pre><code>refreshenv  # if you have Chocolatey\n# Or restart terminal\n</code></pre> <p>macOS/Linux:</p> <pre><code>source ~/.bashrc  # or ~/.zshrc\n</code></pre>"},{"location":"getting-started/03-uv/#sync-fails","title":"Sync Fails","text":"<pre><code># Update uv\npip install --upgrade uv\n\n# Clear cache and retry\nuv cache clean\nuv sync --all-groups\n</code></pre>"},{"location":"getting-started/03-uv/#missing-dependencies","title":"Missing Dependencies","text":"<pre><code># Ensure lock file is current\nuv lock\n\n# Then sync\nuv sync --all-groups\n</code></pre>"},{"location":"getting-started/03-uv/#best-practices","title":"Best Practices","text":"<ol> <li>Use <code>uv sync</code> as default: Most reliable and reproducible</li> <li>Commit <code>pyproject.toml</code> and <code>uv.lock</code>: Ensures team consistency</li> <li>Run <code>uv sync</code> after pulling: Get latest dependencies</li> <li>Use <code>uv add</code> to add packages: Automatically updates pyproject.toml</li> <li>Specify Python version: Use <code>uv venv --python 3.11</code> for team consistency</li> <li>Use dependency groups: Organize optional dependencies (dev, docs, ds)</li> </ol>"},{"location":"getting-started/03-uv/#recommended-team-workflow","title":"Recommended Team Workflow","text":"<pre><code># Initial setup\ngit clone &lt;repo&gt;\ncd Data-Wizardry-with-Python\nuv sync --all-groups\n\n# Daily work\nuv run jupyter lab  # No activation needed\n\n# Adding a dependency\nuv add new-package\ngit add pyproject.toml uv.lock\ngit commit -m \"Add new-package\"\n\n# After pulling changes\nuv sync\n</code></pre>"},{"location":"getting-started/03-uv/#example-complete-setup","title":"Example: Complete Setup","text":"<pre><code># 1. Clone repository\ngit clone https://gitlab.com/your-org/Data-Wizardry-with-Python.git\ncd Data-Wizardry-with-Python\n\n# 2. Sync dependencies\nuv sync --all-groups\n\n# 3. Verify setup\nuv run python -c \"import pandas; print(f'pandas {pandas.__version__}')\"\n\n# 4. Start working\nuv run jupyter lab\n</code></pre>"},{"location":"getting-started/03-uv/#next-steps","title":"Next Steps","text":"<p>Now that uv is configured:</p> <ol> <li>Configure VS Code: Continue to Running Notebooks</li> <li>Start learning: Try the Quick Start Guide</li> <li>Open a notebook: Navigate to <code>notebooks/01_into_and_data_loading.ipynb</code></li> </ol>"},{"location":"getting-started/04-notebooks/","title":"Running Jupyter Notebooks","text":"<p>This guide covers how to work with Jupyter notebooks using VS Code, our recommended setup for the team.</p>"},{"location":"getting-started/04-notebooks/#prerequisites","title":"Prerequisites","text":"<p>Before starting, make sure you have:</p> <ul> <li>\u2705 Python installed (see Installing Python)</li> <li>\u2705 uv set up with dependencies installed (see Using uv)</li> <li>\u2705 VS Code installed</li> </ul>"},{"location":"getting-started/04-notebooks/#setting-up-vs-code-for-jupyter","title":"Setting Up VS Code for Jupyter","text":""},{"location":"getting-started/04-notebooks/#install-vs-code","title":"Install VS Code","text":"<p>Download from code.visualstudio.com or install via Company Portal.</p>"},{"location":"getting-started/04-notebooks/#install-required-extensions","title":"Install Required Extensions","text":"<p>Open VS Code and install these extensions:</p> <ol> <li>Python (by Microsoft) - Python language support</li> <li>Jupyter (by Microsoft) - Notebook support in VS Code</li> <li>Pylance (by Microsoft) - Advanced Python IntelliSense</li> </ol> <p>To install:</p> <ul> <li>Click the Extensions icon in the sidebar (or press <code>Ctrl+Shift+X</code>)</li> <li>Search for each extension by name</li> <li>Click Install</li> </ul>"},{"location":"getting-started/04-notebooks/#opening-the-project","title":"Opening the Project","text":"<ol> <li>Open the project folder:</li> <li><code>File &gt; Open Folder</code> (or <code>Ctrl+K Ctrl+O</code>)</li> <li> <p>Navigate to and select <code>Data-Wizardry-with-Python</code></p> </li> <li> <p>Select Python interpreter:</p> </li> <li>Press <code>Ctrl+Shift+P</code> to open the Command Palette</li> <li>Type \"Python: Select Interpreter\"</li> <li>Choose your virtual environment (should show <code>.venv</code> or similar)</li> </ol>"},{"location":"getting-started/04-notebooks/#working-with-notebooks","title":"Working with Notebooks","text":""},{"location":"getting-started/04-notebooks/#opening-a-notebook","title":"Opening a Notebook","text":"<p>In the VS Code Explorer sidebar:</p> <ol> <li>Navigate to the <code>notebooks/</code> folder</li> <li>Click any <code>.ipynb</code> file to open it</li> <li>The notebook opens directly in VS Code - no browser needed!</li> </ol>"},{"location":"getting-started/04-notebooks/#running-cells","title":"Running Cells","text":"<p>Multiple ways to run cells:</p> <ul> <li>Click the \u25b6 play button next to the cell</li> <li>Press <code>Shift+Enter</code>: Run cell and move to next</li> <li>Press <code>Ctrl+Enter</code>: Run cell and stay on current cell</li> <li>Press <code>Alt+Enter</code>: Run cell and insert new cell below</li> </ul>"},{"location":"getting-started/04-notebooks/#creating-a-new-notebook","title":"Creating a New Notebook","text":""},{"location":"getting-started/04-notebooks/#option-1-via-explorer","title":"Option 1: Via Explorer","text":"<ol> <li>Right-click in the <code>notebooks/</code> folder</li> <li>Select New File</li> <li>Name it with <code>.ipynb</code> extension (e.g., <code>my_analysis.ipynb</code>)</li> </ol>"},{"location":"getting-started/04-notebooks/#option-2-via-command-palette","title":"Option 2: Via Command Palette","text":"<ol> <li>Press <code>Ctrl+Shift+P</code></li> <li>Type \"Jupyter: Create New Blank Notebook\"</li> <li>Save it in the <code>notebooks/</code> folder</li> </ol>"},{"location":"getting-started/04-notebooks/#vs-code-jupyter-features","title":"VS Code Jupyter Features","text":""},{"location":"getting-started/04-notebooks/#variable-explorer","title":"Variable Explorer","text":"<p>View all variables in your notebook:</p> <ul> <li>Click Variables button in the notebook toolbar</li> <li>See values, types, and sizes of all variables</li> <li>Click any variable to inspect it in detail</li> </ul>"},{"location":"getting-started/04-notebooks/#intellisense-code-completion","title":"IntelliSense (Code Completion)","text":"<p>As you type, VS Code suggests completions:</p> <ul> <li>Methods: Type <code>df.</code> to see all DataFrame methods</li> <li>Variables: Start typing a variable name for suggestions</li> <li>Imports: Auto-complete module and function names</li> </ul> <p>Press <code>Ctrl+Space</code> to manually trigger suggestions.</p>"},{"location":"getting-started/04-notebooks/#keyboard-shortcuts","title":"Keyboard Shortcuts","text":"<p>Command Mode (press <code>Esc</code> to enter):</p> <ul> <li><code>A</code>: Insert cell above</li> <li><code>B</code>: Insert cell below</li> <li><code>DD</code>: Delete cell</li> <li><code>M</code>: Convert cell to Markdown</li> <li><code>Y</code>: Convert cell to Code</li> <li><code>Z</code>: Undo cell deletion</li> </ul> <p>Edit Mode (press <code>Enter</code> on a cell to enter):</p> <ul> <li><code>Ctrl+/</code>: Comment/uncomment code</li> <li><code>Tab</code>: Indent or autocomplete</li> <li><code>Shift+Tab</code>: Unindent</li> </ul> <p>Running Cells:</p> <ul> <li><code>Shift+Enter</code>: Run cell, select below</li> <li><code>Ctrl+Enter</code>: Run cell, stay on current</li> <li><code>Alt+Enter</code>: Run cell, insert below</li> </ul>"},{"location":"getting-started/04-notebooks/#other-useful-features","title":"Other Useful Features","text":"<p>Markdown Cells: Create documentation alongside code</p> <pre><code># Heading\n**bold** and *italic*\n- Bullet points\n[Links](https://example.com)\n</code></pre> <p>Code Folding: Click arrows next to line numbers to collapse sections</p> <p>Multiple Cursors: <code>Alt+Click</code> to add cursors</p> <p>Find and Replace: <code>Ctrl+F</code> to search, <code>Ctrl+H</code> to replace</p>"},{"location":"getting-started/04-notebooks/#your-first-notebook","title":"Your First Notebook","text":"<p>Try this in a new notebook:</p> <p>Cell 1 (Markdown):</p> <pre><code># My First Analysis\nExploring data with pandas\n</code></pre> <p>Cell 2 (Code):</p> <pre><code>import pandas as pd\nimport numpy as np\n\n# Create sample data\ndata = {\n    'Name': ['Alice', 'Bob', 'Charlie'],\n    'Age': [25, 30, 35],\n    'Department': ['Sales', 'IT', 'HR']\n}\n\ndf = pd.DataFrame(data)\ndf\n</code></pre> <p>Cell 3 (Code):</p> <pre><code># Summary statistics\ndf.describe()\n</code></pre> <p>Run each cell with <code>Shift+Enter</code> and watch the output appear below!</p>"},{"location":"getting-started/04-notebooks/#tips-for-effective-notebook-use","title":"Tips for Effective Notebook Use","text":""},{"location":"getting-started/04-notebooks/#organization","title":"Organization","text":"<ul> <li>One concept per cell: Keep cells focused and small</li> <li>Use Markdown cells: Document what you're doing and why</li> <li>Clear outputs before committing: <code>Ctrl+Shift+P</code> \u2192 \"Jupyter: Clear All Outputs\"</li> </ul>"},{"location":"getting-started/04-notebooks/#best-practices","title":"Best Practices","text":"<ul> <li>Restart kernel regularly: <code>Ctrl+Shift+P</code> \u2192 \"Jupyter: Restart Kernel\"</li> <li>Run cells in order: Avoid running cells out of sequence</li> <li>Save frequently: <code>Ctrl+S</code> saves your notebook</li> <li>Use meaningful names: <code>customer_analysis.ipynb</code> not <code>untitled1.ipynb</code></li> </ul>"},{"location":"getting-started/04-notebooks/#getting-help","title":"Getting Help","text":"<p>In a code cell, you can get help on any function:</p> <pre><code># Add ? for quick help\npd.read_csv?\n\n# Or use help()\nhelp(pd.DataFrame)\n</code></pre>"},{"location":"getting-started/04-notebooks/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/04-notebooks/#kernel-wont-start","title":"Kernel Won't Start","text":"<ol> <li>Make sure your virtual environment is selected as the interpreter</li> <li>Try: <code>Ctrl+Shift+P</code> \u2192 \"Jupyter: Restart Kernel\"</li> <li>If that fails, restart VS Code</li> </ol>"},{"location":"getting-started/04-notebooks/#missing-package-error","title":"Missing Package Error","text":"<p>If you see <code>ModuleNotFoundError</code>:</p> <ol> <li>Open a terminal in VS Code (<code>Ctrl+`</code>)</li> <li>Activate the virtual environment if not already active</li> <li>Install the package: <code>uv pip install package-name</code></li> <li>Restart the kernel</li> </ol>"},{"location":"getting-started/04-notebooks/#wrong-python-environment","title":"Wrong Python Environment","text":"<ol> <li>Check the interpreter in the bottom-right of VS Code</li> <li>Press <code>Ctrl+Shift+P</code> \u2192 \"Python: Select Interpreter\"</li> <li>Choose the <code>.venv</code> environment</li> <li>Restart the kernel</li> </ol>"},{"location":"getting-started/04-notebooks/#alternative-jupyter-lab-browser-based","title":"Alternative: Jupyter Lab (Browser-Based)","text":"<p>If you prefer the traditional browser interface:</p> <ol> <li>Open terminal in VS Code (<code>Ctrl+`</code>)</li> <li>Activate your virtual environment</li> <li>Run:</li> </ol> <pre><code>jupyter lab\n</code></pre> <p>Your browser opens to Jupyter Lab. Navigate to <code>notebooks/</code> and start working.</p> <p>Note: We recommend VS Code for better Git integration and unified workflow, but Jupyter Lab is available if you prefer it.</p>"},{"location":"getting-started/04-notebooks/#next-steps","title":"Next Steps","text":"<p>Now you're ready to:</p> <ol> <li>Start learning: Try the Quick Start Guide</li> <li>Open a tutorial: Check <code>notebooks/01_into_and_data_loading.ipynb</code></li> <li>Explore pandas: Read the Pandas Overview</li> </ol>"},{"location":"getting-started/05-quickstart/","title":"Quick Start Guide","text":"<p>Your first steps with Python for data analysis. This guide assumes you've completed the Installation Guide.</p>"},{"location":"getting-started/05-quickstart/#before-you-begin","title":"Before You Begin","text":"<p>Make sure you have:</p> <ul> <li>\u2705 Python and Git installed</li> <li>\u2705 Virtual environment created and activated</li> <li>\u2705 VS Code set up with Jupyter extension</li> <li>\u2705 Repository cloned</li> </ul> <p>If not, see the Installation Guide.</p>"},{"location":"getting-started/05-quickstart/#your-first-data-analysis","title":"Your First Data Analysis","text":""},{"location":"getting-started/05-quickstart/#open-vs-code","title":"Open VS Code","text":"<ol> <li>Launch VS Code</li> <li><code>File &gt; Open Folder</code> \u2192 select <code>Data-Wizardry-with-Python</code></li> <li>Select your Python interpreter (<code>Ctrl+Shift+P</code> \u2192 \"Python: Select Interpreter\" \u2192 choose <code>.venv</code>)</li> </ol>"},{"location":"getting-started/05-quickstart/#create-your-first-notebook","title":"Create Your First Notebook","text":"<ol> <li>In Explorer, right-click the <code>notebooks/</code> folder</li> <li>Select New File</li> <li>Name it <code>my_first_analysis.ipynb</code></li> <li>The notebook opens in VS Code</li> </ol>"},{"location":"getting-started/05-quickstart/#cell-1-import-libraries","title":"Cell 1 - Import libraries","text":"<pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Display settings\npd.options.display.max_columns = 50\npd.options.display.width = 120\n\nprint(\"\u2713 Libraries loaded successfully!\")\n</code></pre> <p>Run the cell with <code>Shift+Enter</code>. You should see the success message.</p> <p>Cell 2 - Load the sample data:</p> <pre><code># Load demographic data\ndf = pd.read_csv('data/socio_demos.csv')\n\n# Quick look at the data\ndf.head()\n</code></pre> <p>Cell 3 - Explore the data structure:</p> <p>Cell 1 - Import libraries:</p> <p>Cell 3 - Explore the data structure:</p> <pre><code># Shape and info\nprint(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")\nprint(\"\\nColumn types:\")\nprint(df.dtypes)\nprint(\"\\nMissing values:\")\nprint(df.isnull().sum())\n</code></pre> <p>Cell 4 - Basic statistics:</p> <pre><code># Summary statistics\ndf.describe()\n</code></pre> <p>Cell 5 - Create a simple visualization:</p> <pre><code># Example: visualize a distribution (adjust column name as needed)\ndf.select_dtypes(include=[np.number]).iloc[:, 0].hist(bins=20, figsize=(8, 4))\nplt.title('Distribution of First Numeric Column')\nplt.xlabel('Value')\nplt.ylabel('Frequency')\nplt.tight_layout()\nplt.show()\n</code></pre> <p>Congratulations! You've just completed your first data analysis in Python.</p>"},{"location":"getting-started/05-quickstart/#essential-pandas-operations","title":"Essential pandas Operations","text":""},{"location":"getting-started/05-quickstart/#selecting-data","title":"Selecting Data","text":"<pre><code># Select a single column\ndf['column_name']\n\n# Select multiple columns\ndf[['col1', 'col2', 'col3']]\n\n# Select rows by condition\ndf[df['age'] &gt; 30]\n\n# Select rows and columns together\ndf.loc[df['age'] &gt; 30, ['name', 'age', 'department']]\n</code></pre>"},{"location":"getting-started/05-quickstart/#filtering-and-sorting","title":"Filtering and Sorting","text":"<pre><code># Filter rows\nyoung_employees = df[df['age'] &lt; 30]\n\n# Multiple conditions (use &amp; for AND, | for OR)\nfiltered = df[(df['age'] &gt; 25) &amp; (df['department'] == 'Sales')]\n\n# Sort by column\ndf.sort_values('age', ascending=False)\n\n# Sort by multiple columns\ndf.sort_values(['department', 'age'])\n</code></pre>"},{"location":"getting-started/05-quickstart/#grouping-and-aggregating","title":"Grouping and Aggregating","text":"<pre><code># Group by one column\ndf.groupby('department')['salary'].mean()\n\n# Group by multiple columns\ndf.groupby(['department', 'location'])['salary'].agg(['mean', 'count'])\n\n# Multiple aggregations\ndf.groupby('department').agg({\n    'salary': ['mean', 'min', 'max'],\n    'age': 'mean'\n})\n</code></pre>"},{"location":"getting-started/05-quickstart/#creating-new-columns","title":"Creating New Columns","text":"<pre><code># Simple calculation\ndf['bonus'] = df['salary'] * 0.10\n\n# Conditional column\ndf['category'] = df['age'].apply(lambda x: 'Senior' if x &gt; 40 else 'Junior')\n\n# Using np.where for conditions\ndf['status'] = np.where(df['salary'] &gt; 60000, 'High', 'Standard')\n</code></pre>"},{"location":"getting-started/05-quickstart/#working-with-real-data","title":"Working with Real Data","text":""},{"location":"getting-started/05-quickstart/#load-your-own-data","title":"Load Your Own Data","text":"<pre><code># CSV file\ndf = pd.read_csv('path/to/your_file.csv')\n\n# Excel file\ndf = pd.read_excel('path/to/your_file.xlsx', sheet_name='Sheet1')\n\n# Specify encoding if needed\ndf = pd.read_csv('file.csv', encoding='utf-8')\n\n# Skip rows or specify column names\ndf = pd.read_csv('file.csv', skiprows=2, names=['col1', 'col2', 'col3'])\n</code></pre>"},{"location":"getting-started/05-quickstart/#handle-missing-data","title":"Handle Missing Data","text":"<pre><code># Check for missing values\ndf.isnull().sum()\n\n# Drop rows with any missing values\ndf_clean = df.dropna()\n\n# Drop rows where specific column is missing\ndf_clean = df.dropna(subset=['important_column'])\n\n# Fill missing values\ndf['column'].fillna(0, inplace=True)  # With a value\ndf['column'].fillna(df['column'].mean(), inplace=True)  # With mean\n</code></pre>"},{"location":"getting-started/05-quickstart/#export-results","title":"Export Results","text":"<pre><code># Save to CSV\ndf.to_csv('output.csv', index=False)\n\n# Save to Excel\ndf.to_excel('output.xlsx', sheet_name='Results', index=False)\n\n# Save specific columns\ndf[['col1', 'col2']].to_csv('subset.csv', index=False)\n</code></pre>"},{"location":"getting-started/05-quickstart/#common-tasks-cheat-sheet","title":"Common Tasks Cheat Sheet","text":"Task Code Load CSV <code>pd.read_csv('file.csv')</code> First 5 rows <code>df.head()</code> Last 5 rows <code>df.tail()</code> Shape (rows, cols) <code>df.shape</code> Column names <code>df.columns</code> Data types <code>df.dtypes</code> Summary stats <code>df.describe()</code> Missing values <code>df.isnull().sum()</code> Unique values <code>df['col'].unique()</code> Value counts <code>df['col'].value_counts()</code> Filter rows <code>df[df['col'] &gt; 10]</code> Sort <code>df.sort_values('col')</code> Group by <code>df.groupby('col').mean()</code> New column <code>df['new'] = df['a'] + df['b']</code> Drop column <code>df.drop('col', axis=1)</code> Save to CSV <code>df.to_csv('out.csv', index=False)</code>"},{"location":"getting-started/05-quickstart/#getting-help","title":"Getting Help","text":""},{"location":"getting-started/05-quickstart/#in-your-notebook","title":"In Your Notebook","text":"<pre><code># Quick help on any function\npd.read_csv?\n\n# Detailed help\nhelp(pd.DataFrame)\n\n# See all methods of an object\ndir(df)\n</code></pre>"},{"location":"getting-started/05-quickstart/#keyboard-shortcuts-vs-code","title":"Keyboard Shortcuts (VS Code)","text":"<ul> <li><code>Shift+Enter</code>: Run cell and move to next</li> <li><code>Ctrl+Enter</code>: Run cell and stay</li> <li><code>Esc then A</code>: Insert cell above</li> <li><code>Esc then B</code>: Insert cell below</li> <li><code>Esc then DD</code>: Delete cell</li> <li><code>Esc then M</code>: Convert to Markdown</li> <li><code>Esc then Y</code>: Convert to Code</li> </ul>"},{"location":"getting-started/05-quickstart/#next-steps","title":"Next Steps","text":"<p>Now that you've got the basics:</p> <ol> <li>Explore the notebooks: Try <code>notebooks/01_into_and_data_loading.ipynb</code></li> <li>Learn Python basics: Read Python Basics for Analysts</li> <li>Master pandas: Check out the Pandas Overview</li> <li>Coming from R?: See the R to Python Guide</li> <li>Coming from SPSS?: See the SPSS to Python Guide</li> </ol>"},{"location":"getting-started/05-quickstart/#tips-for-success","title":"Tips for Success","text":"<ol> <li>Experiment: Try modifying the code examples</li> <li>Use Markdown cells: Document your thought process</li> <li>Save often: <code>Ctrl+S</code> to save your notebook</li> <li>Restart kernel: If things get weird, restart the kernel (<code>Ctrl+Shift+P</code> \u2192 \"Jupyter: Restart Kernel\")</li> <li>Check data types: Many errors come from unexpected data types</li> <li>Read error messages: They usually point to the problem</li> </ol> <p>Happy analyzing! \ud83c\udf89</p>"},{"location":"getting-started/git-guide/","title":"Git Guide for Data Analytics","text":"<p>This guide introduces Git version control for colleagues who may be new to it. Git helps you track changes, collaborate with others, and manage your code safely.</p>"},{"location":"getting-started/git-guide/#what-is-git","title":"What is Git?","text":"<p>Git is a version control system that:</p> <ul> <li>Tracks changes to your code over time</li> <li>Enables collaboration with team members</li> <li>Prevents data loss through history and backups</li> <li>Manages different versions (branches) of your project</li> </ul> <p>Think of it as \"track changes\" for code, but much more powerful.</p>"},{"location":"getting-started/git-guide/#installing-git","title":"Installing Git","text":""},{"location":"getting-started/git-guide/#windows","title":"Windows","text":"<p>Download from git-scm.com and run the installer.</p> <p>Recommended settings during installation:</p> <ul> <li>Use Visual Studio Code as Git's default editor</li> <li>Override the default branch name: use <code>main</code></li> <li>Use bundled OpenSSH</li> <li>Use the OpenSSL library</li> <li>Checkout Windows-style, commit Unix-style line endings</li> <li>Use MinTTY terminal</li> <li>Default pull behavior: Fast-forward only</li> </ul>"},{"location":"getting-started/git-guide/#macos","title":"macOS","text":"<pre><code># Using Homebrew (recommended)\nbrew install git\n\n# Or download from git-scm.com\n</code></pre>"},{"location":"getting-started/git-guide/#linux","title":"Linux","text":"<pre><code># Debian/Ubuntu\nsudo apt-get install git\n\n# Fedora\nsudo dnf install git\n</code></pre>"},{"location":"getting-started/git-guide/#verify-installation","title":"Verify Installation","text":"<pre><code>git --version\n</code></pre>"},{"location":"getting-started/git-guide/#first-time-setup","title":"First-Time Setup","text":"<p>Configure your identity (required for commits):</p> <pre><code># Set your name\ngit config --global user.name \"Your Name\"\n\n# Set your email\ngit config --global user.email \"your.email@example.com\"\n\n# Set default branch name to 'main'\ngit config --global init.defaultBranch main\n\n# Set VS Code as default editor\ngit config --global core.editor \"code --wait\"\n</code></pre>"},{"location":"getting-started/git-guide/#basic-git-workflow","title":"Basic Git Workflow","text":""},{"location":"getting-started/git-guide/#1-clone-a-repository","title":"1. Clone a Repository","text":"<p>Download an existing project from GitLab:</p> <pre><code>git clone https://gitlab.com/your-org/Data-Wizardry-with-Python.git\ncd Data-Wizardry-with-Python\n</code></pre>"},{"location":"getting-started/git-guide/#2-check-status","title":"2. Check Status","text":"<p>See what files have changed:</p> <pre><code>git status\n</code></pre>"},{"location":"getting-started/git-guide/#3-stage-changes","title":"3. Stage Changes","text":"<p>Add files to be committed:</p> <pre><code># Stage a specific file\ngit add filename.py\n\n# Stage all changes\ngit add .\n\n# Stage multiple files\ngit add file1.py file2.py\n</code></pre>"},{"location":"getting-started/git-guide/#4-commit-changes","title":"4. Commit Changes","text":"<p>Save your staged changes with a message:</p> <pre><code>git commit -m \"Add data cleaning function\"\n</code></pre> <p>Good commit messages:</p> <ul> <li>\"Fix bug in data import\"</li> <li>\"Add visualization for sales trends\"</li> <li>\"Update documentation for installation\"</li> </ul> <p>Bad commit messages:</p> <ul> <li>\"Update\"</li> <li>\"Changes\"</li> <li>\"asdfasdf\"</li> </ul>"},{"location":"getting-started/git-guide/#5-push-to-remote","title":"5. Push to Remote","text":"<p>Send your commits to GitLab:</p> <pre><code>git push\n</code></pre>"},{"location":"getting-started/git-guide/#6-pull-latest-changes","title":"6. Pull Latest Changes","text":"<p>Get updates from GitLab:</p> <pre><code>git pull\n</code></pre>"},{"location":"getting-started/git-guide/#working-with-branches","title":"Working with Branches","text":"<p>Branches let you work on features without affecting the main code.</p>"},{"location":"getting-started/git-guide/#create-and-switch-to-a-new-branch","title":"Create and Switch to a New Branch","text":"<pre><code># Create and switch to new branch\ngit checkout -b feature/new-analysis\n\n# Or in newer Git versions\ngit switch -c feature/new-analysis\n</code></pre>"},{"location":"getting-started/git-guide/#switch-between-branches","title":"Switch Between Branches","text":"<pre><code># Switch to existing branch\ngit checkout main\n\n# Or in newer Git versions\ngit switch main\n</code></pre>"},{"location":"getting-started/git-guide/#list-branches","title":"List Branches","text":"<pre><code># Local branches\ngit branch\n\n# All branches (local and remote)\ngit branch -a\n</code></pre>"},{"location":"getting-started/git-guide/#merge-branches","title":"Merge Branches","text":"<pre><code># Switch to the branch you want to merge into\ngit checkout main\n\n# Merge another branch into current branch\ngit merge feature/new-analysis\n</code></pre>"},{"location":"getting-started/git-guide/#delete-a-branch","title":"Delete a Branch","text":"<pre><code># Delete local branch\ngit branch -d feature/new-analysis\n\n# Force delete (if not merged)\ngit branch -D feature/new-analysis\n</code></pre>"},{"location":"getting-started/git-guide/#using-git-in-vs-code","title":"Using Git in VS Code","text":"<p>VS Code has excellent built-in Git support. This is the recommended way to use Git for this project.</p>"},{"location":"getting-started/git-guide/#visual-interface","title":"Visual Interface","text":"<ol> <li> <p>Source Control Panel: Click the branch icon in the left sidebar (or press <code>Ctrl+Shift+G</code>)</p> </li> <li> <p>See Changes: Modified files appear in the Source Control panel</p> </li> <li> <p>Stage Changes:</p> </li> <li>Hover over a file</li> <li> <p>Click the <code>+</code> icon to stage</p> </li> <li> <p>Commit:</p> </li> <li>Type a commit message in the text box</li> <li> <p>Press <code>Ctrl+Enter</code> or click the checkmark \u2713</p> </li> <li> <p>Push/Pull:</p> </li> <li>Click the <code>...</code> menu in Source Control panel</li> <li>Select \"Push\" or \"Pull\"</li> </ol>"},{"location":"getting-started/git-guide/#vs-code-git-features","title":"VS Code Git Features","text":"<ul> <li>Diff View: Click a modified file to see what changed (side-by-side comparison)</li> <li>Inline Annotations: See who changed each line (GitLens extension recommended)</li> <li>Branch Switching: Click branch name in bottom-left corner</li> <li>Merge Conflicts: VS Code highlights conflicts and offers resolution options</li> </ul>"},{"location":"getting-started/git-guide/#recommended-vs-code-extensions","title":"Recommended VS Code Extensions","text":"<ol> <li>GitLens (by GitKraken)</li> <li>Advanced Git visualization</li> <li>Blame annotations</li> <li> <p>Repository history</p> </li> <li> <p>Git Graph (by mhutchie)</p> </li> <li>Visual branch graph</li> <li>Easy branch management</li> </ol> <p>To install: <code>Ctrl+Shift+X</code> \u2192 Search \u2192 Install</p>"},{"location":"getting-started/git-guide/#common-git-commands-quick-reference","title":"Common Git Commands Quick Reference","text":"Task Command Clone repository <code>git clone &lt;url&gt;</code> Check status <code>git status</code> Stage file <code>git add &lt;file&gt;</code> Stage all changes <code>git add .</code> Commit <code>git commit -m \"message\"</code> Push to remote <code>git push</code> Pull from remote <code>git pull</code> Create branch <code>git checkout -b &lt;branch-name&gt;</code> Switch branch <code>git checkout &lt;branch-name&gt;</code> List branches <code>git branch</code> Merge branch <code>git merge &lt;branch-name&gt;</code> View history <code>git log</code> View history (concise) <code>git log --oneline</code> Discard changes in file <code>git checkout -- &lt;file&gt;</code> Undo last commit (keep changes) <code>git reset --soft HEAD~1</code>"},{"location":"getting-started/git-guide/#working-with-gitlab","title":"Working with GitLab","text":"<p>This repository will be hosted on GitLab. GitLab is similar to GitHub but offers some additional features.</p>"},{"location":"getting-started/git-guide/#key-gitlab-concepts","title":"Key GitLab Concepts","text":"<p>Repository: Your project's home on GitLab</p> <p>Merge Request (MR): Like GitHub's Pull Request - propose changes to be merged</p> <p>Issues: Track bugs, features, and tasks</p> <p>CI/CD: Automated testing and deployment (we'll use this for documentation)</p>"},{"location":"getting-started/git-guide/#creating-a-merge-request","title":"Creating a Merge Request","text":"<ol> <li>Push your branch:</li> </ol> <pre><code>git push -u origin feature/your-feature\n</code></pre> <ol> <li>In GitLab:</li> <li>Navigate to your repository</li> <li>Click \"Create merge request\"</li> <li>Fill in title and description</li> <li>Assign reviewers</li> <li> <p>Click \"Create merge request\"</p> </li> <li> <p>After Review:</p> </li> <li>Address any feedback</li> <li>Push additional commits if needed</li> <li>Once approved, click \"Merge\"</li> </ol>"},{"location":"getting-started/git-guide/#clone-from-gitlab","title":"Clone from GitLab","text":"<pre><code># HTTPS (recommended for beginners)\ngit clone https://gitlab.com/your-org/Data-Wizardry-with-Python.git\n\n# SSH (after setting up SSH keys)\ngit clone git@gitlab.com:your-org/Data-Wizardry-with-Python.git\n</code></pre>"},{"location":"getting-started/git-guide/#set-up-ssh-keys-for-gitlab","title":"Set Up SSH Keys for GitLab","text":"<p>SSH keys provide secure authentication without passwords.</p> <ol> <li>Generate SSH key:</li> </ol> <pre><code>ssh-keygen -t ed25519 -C \"your.email@example.com\"\n</code></pre> <p>Press Enter to accept defaults.</p> <ol> <li>Copy public key:</li> </ol> <pre><code># macOS\npbcopy &lt; ~/.ssh/id_ed25519.pub\n\n# Linux\ncat ~/.ssh/id_ed25519.pub\n\n# Windows (Git Bash)\ncat ~/.ssh/id_ed25519.pub | clip\n</code></pre> <ol> <li>Add to GitLab:</li> <li>Go to GitLab \u2192 Settings \u2192 SSH Keys</li> <li>Paste your public key</li> <li>Give it a title (e.g., \"Work Laptop\")</li> <li> <p>Click \"Add key\"</p> </li> <li> <p>Test connection:</p> </li> </ol> <pre><code>ssh -T git@gitlab.td.gfk.com\n</code></pre>"},{"location":"getting-started/git-guide/#best-practices","title":"Best Practices","text":""},{"location":"getting-started/git-guide/#dos","title":"Do's","text":"<p>\u2705 Commit often: Small, focused commits are better than large ones</p> <p>\u2705 Write clear commit messages: Explain what and why</p> <p>\u2705 Pull before you push: Stay up to date with team changes</p> <p>\u2705 Use branches: Keep experimental work separate</p> <p>\u2705 Review changes before committing: Use <code>git status</code> and <code>git diff</code></p>"},{"location":"getting-started/git-guide/#donts","title":"Don'ts","text":"<p>\u274c Don't commit sensitive data: No passwords, API keys, or credentials</p> <p>\u274c Don't commit large files: Use Git LFS for large datasets (or keep them local)</p> <p>\u274c Don't work directly on main: Use feature branches</p> <p>\u274c Don't force push: Unless you really know what you're doing</p> <p>\u274c Don't commit generated files: Build outputs, <code>__pycache__</code>, <code>.venv</code>, etc.</p>"},{"location":"getting-started/git-guide/#ignoring-files-gitignore","title":"Ignoring Files (.gitignore)","text":"<p>The <code>.gitignore</code> file tells Git which files to ignore. Our project already has one that ignores:</p> <pre><code># Virtual environments\nvenv/\n.venv/\nenv/\n\n# Python cache\n__pycache__/\n*.pyc\n*.pyo\n\n# Jupyter\n.ipynb_checkpoints/\n\n# IDE\n.vscode/\n.idea/\n\n# OS files\n.DS_Store\nThumbs.db\n\n# Data files (if large)\n*.csv\n*.xlsx\n</code></pre> <p>Note: The <code>data/</code> folder CSV files are tracked because they're small sample files for learning.</p>"},{"location":"getting-started/git-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/git-guide/#permission-denied-when-pushing","title":"\"Permission denied\" when pushing","text":"<ul> <li>Check that you have write access to the repository</li> <li>Verify your SSH keys are set up correctly</li> <li>Try HTTPS instead of SSH</li> </ul>"},{"location":"getting-started/git-guide/#merge-conflicts","title":"Merge conflicts","text":"<p>When Git can't automatically merge changes:</p> <ol> <li>VS Code approach (recommended):</li> <li>Open the conflicted file</li> <li>VS Code highlights conflicts</li> <li>Click \"Accept Current Change\", \"Accept Incoming Change\", or \"Accept Both Changes\"</li> <li>Save the file</li> <li> <p>Stage and commit</p> </li> <li> <p>Manual approach:</p> </li> </ol> <pre><code># Edit the conflicted file\n# Look for conflict markers: &lt;&lt;&lt;&lt;&lt;&lt;&lt;, =======, &gt;&gt;&gt;&gt;&gt;&gt;&gt;\n# Choose which code to keep\n# Remove conflict markers\ngit add &lt;resolved-file&gt;\ngit commit -m \"Resolve merge conflict\"\n</code></pre>"},{"location":"getting-started/git-guide/#accidentally-committed-sensitive-data","title":"Accidentally committed sensitive data","text":"<pre><code># Remove file from Git but keep it locally\ngit rm --cached sensitive_file.txt\n\n# Add to .gitignore\necho \"sensitive_file.txt\" &gt;&gt; .gitignore\n\n# Commit the removal\ngit commit -m \"Remove sensitive file from tracking\"\n\n# Push\ngit push\n</code></pre> <p>Warning: This doesn't remove the file from history. For complete removal, contact your GitLab admin.</p>"},{"location":"getting-started/git-guide/#want-to-undo-local-changes","title":"Want to undo local changes","text":"<pre><code># Discard changes in a specific file\ngit checkout -- filename.py\n\n# Discard all uncommitted changes (CAREFUL!)\ngit reset --hard\n</code></pre>"},{"location":"getting-started/git-guide/#learning-resources","title":"Learning Resources","text":"<ul> <li>Git Official Documentation</li> <li>GitLab Documentation</li> <li>VS Code Git Tutorial</li> <li>Interactive Git Tutorial</li> </ul>"},{"location":"getting-started/git-guide/#next-steps","title":"Next Steps","text":"<p>Now that you understand Git:</p> <ol> <li>\u2705 Git installed and configured</li> <li>\u2705 Repository cloned</li> <li>\u2705 VS Code Git integration ready</li> <li>\u2705 Basic workflow understood</li> </ol> <p>Continue with:</p> <ul> <li>Installation Guide - Set up Python and dependencies</li> <li>Quick Start Guide - Start coding!</li> </ul> <p>Remember: Git might seem complex at first, but you'll mainly use just a few commands daily. The VS Code integration makes it even easier - you can do most Git operations without touching the command line!</p>"},{"location":"guides/python_basics_for_analysts/","title":"Python Basics for Analysts","text":"<p>A practical guide to Python fundamentals for analysts transitioning from R or SPSS. This guide focuses on concepts relevant to data analysis work.</p>"},{"location":"guides/python_basics_for_analysts/#why-python-for-data-analysis","title":"Why Python for Data Analysis?","text":"<ul> <li>Versatile: Data analysis, automation, web apps, machine learning</li> <li>Large ecosystem: pandas, NumPy, scikit-learn, and thousands more packages</li> <li>Industry standard: Widely used in tech, finance, healthcare, research</li> <li>Open source: Free, with excellent community support</li> <li>Readable: Clear syntax that's easy to learn and maintain</li> </ul>"},{"location":"guides/python_basics_for_analysts/#python-syntax-essentials","title":"Python Syntax Essentials","text":""},{"location":"guides/python_basics_for_analysts/#variables-and-assignment","title":"Variables and Assignment","text":"<pre><code># No need to declare types - Python infers them\nname = \"Alice\"          # string\nage = 25                # integer\nheight = 1.65           # float\nis_analyst = True       # boolean\n\n# Multiple assignment\nx, y, z = 1, 2, 3\n\n# Update variable\ncount = 0\ncount = count + 1  # or count += 1\n</code></pre>"},{"location":"guides/python_basics_for_analysts/#comments","title":"Comments","text":"<pre><code># Single-line comment\n\n\"\"\"\nMulti-line comment\nor docstring\n\"\"\"\n\nx = 5  # Inline comment\n</code></pre>"},{"location":"guides/python_basics_for_analysts/#printing-output","title":"Printing Output","text":"<pre><code>print(\"Hello, world!\")\nprint(f\"Name: {name}, Age: {age}\")  # f-string (recommended)\nprint(\"Value:\", 42, \"Other:\", 3.14)  # Multiple values\n</code></pre>"},{"location":"guides/python_basics_for_analysts/#data-types-for-analysts","title":"Data Types for Analysts","text":""},{"location":"guides/python_basics_for_analysts/#numbers","title":"Numbers","text":"<pre><code># Integers\ncount = 100\nyear = 2024\n\n# Floats\nprice = 99.99\npercentage = 0.15\n\n# Operations\ntotal = 10 + 5          # 15\ndifference = 10 - 5     # 5\nproduct = 10 * 5        # 50\nquotient = 10 / 5       # 2.0 (always float)\nint_division = 10 // 3  # 3 (integer division)\nremainder = 10 % 3      # 1 (modulo)\npower = 2 ** 3          # 8\n\n# Type conversion\nint(\"42\")               # String to int\nfloat(\"3.14\")           # String to float\nstr(42)                 # Int to string\n</code></pre>"},{"location":"guides/python_basics_for_analysts/#strings","title":"Strings","text":"<pre><code># Creating strings\nname = \"Alice\"\nname = 'Alice'  # Single quotes work too\nmultiline = \"\"\"This is\na multiline\nstring\"\"\"\n\n# String operations\nfull_name = \"Alice\" + \" \" + \"Smith\"  # Concatenation\nrepeated = \"Hi! \" * 3                # \"Hi! Hi! Hi! \"\n\n# Common methods\ntext = \"  Hello World  \"\ntext.lower()           # \"  hello world  \"\ntext.upper()           # \"  HELLO WORLD  \"\ntext.strip()           # \"Hello World\"\ntext.replace(\"Hello\", \"Hi\")  # \"  Hi World  \"\ntext.split()           # [\"Hello\", \"World\"]\n\n# String formatting (use f-strings!)\nname = \"Alice\"\nage = 25\nmessage = f\"Hello, {name}! You are {age} years old.\"\nformatted = f\"Price: ${price:.2f}\"  # 2 decimal places\n</code></pre>"},{"location":"guides/python_basics_for_analysts/#lists-like-vectorsarrays","title":"Lists (Like Vectors/Arrays)","text":"<pre><code># Creating lists\nnumbers = [1, 2, 3, 4, 5]\nnames = [\"Alice\", \"Bob\", \"Charlie\"]\nmixed = [1, \"two\", 3.0, True]  # Can mix types\n\n# Accessing elements (0-indexed!)\nnumbers[0]              # 1 (first element)\nnumbers[-1]             # 5 (last element)\nnumbers[1:3]            # [2, 3] (slicing, end exclusive)\nnumbers[:3]             # [1, 2, 3] (first 3)\nnumbers[2:]             # [3, 4, 5] (from index 2 on)\n\n# Modifying\nnumbers[0] = 10         # Change element\nnumbers.append(6)       # Add to end\nnumbers.insert(0, 0)    # Insert at position\nnumbers.remove(3)       # Remove first occurrence\ndel numbers[0]          # Delete by index\nnumbers.pop()           # Remove and return last\n\n# Common operations\nlen(numbers)            # Length\nsum(numbers)            # Sum\nmin(numbers)            # Minimum\nmax(numbers)            # Maximum\nsorted(numbers)         # Returns sorted copy\nnumbers.sort()          # Sort in place\n\n# List comprehension (powerful!)\nsquares = [x**2 for x in range(1, 6)]  # [1, 4, 9, 16, 25]\nevens = [x for x in numbers if x % 2 == 0]\n</code></pre>"},{"location":"guides/python_basics_for_analysts/#dictionaries-like-named-lists-in-r","title":"Dictionaries (Like Named Lists in R)","text":"<pre><code># Creating dictionaries (key-value pairs)\nperson = {\n    \"name\": \"Alice\",\n    \"age\": 25,\n    \"city\": \"NYC\"\n}\n\n# Accessing values\nperson[\"name\"]          # \"Alice\"\nperson.get(\"age\")       # 25\nperson.get(\"country\", \"USA\")  # Default if key doesn't exist\n\n# Modifying\nperson[\"age\"] = 26      # Update value\nperson[\"email\"] = \"alice@example.com\"  # Add new key\ndel person[\"city\"]      # Remove key\n\n# Common operations\nperson.keys()           # All keys\nperson.values()         # All values\nperson.items()          # Key-value pairs\n\"name\" in person        # Check if key exists\n\n# Iterating\nfor key in person:\n    print(key, person[key])\n\nfor key, value in person.items():\n    print(f\"{key}: {value}\")\n</code></pre>"},{"location":"guides/python_basics_for_analysts/#booleans-and-comparisons","title":"Booleans and Comparisons","text":"<pre><code># Boolean values\nis_valid = True\nis_empty = False\n\n# Comparisons\n5 == 5              # True (equal)\n5 != 3              # True (not equal)\n5 &gt; 3               # True (greater than)\n5 &gt;= 5              # True (greater or equal)\n5 &lt; 3               # False (less than)\n5 &lt;= 5              # True (less or equal)\n\n# Logical operators\nTrue and False      # False\nTrue or False       # True\nnot True            # False\n\n# Combining conditions\nage = 25\nif age &gt;= 18 and age &lt; 65:\n    print(\"Working age\")\n\n# Check membership\n\"Alice\" in [\"Alice\", \"Bob\"]  # True\n\"x\" in \"example\"            # True\n</code></pre>"},{"location":"guides/python_basics_for_analysts/#control-flow","title":"Control Flow","text":""},{"location":"guides/python_basics_for_analysts/#if-statements","title":"If Statements","text":"<pre><code>age = 25\n\nif age &lt; 18:\n    print(\"Minor\")\nelif age &lt; 65:\n    print(\"Adult\")\nelse:\n    print(\"Senior\")\n\n# Inline if (ternary operator)\nstatus = \"Adult\" if age &gt;= 18 else \"Minor\"\n\n# Common patterns\nif value is not None:\n    # do something\n\nif len(items) &gt; 0:  # or just: if items:\n    # process items\n</code></pre>"},{"location":"guides/python_basics_for_analysts/#for-loops","title":"For Loops","text":"<pre><code># Loop over list\nfor name in [\"Alice\", \"Bob\", \"Charlie\"]:\n    print(name)\n\n# Loop over range\nfor i in range(5):          # 0, 1, 2, 3, 4\n    print(i)\n\nfor i in range(1, 6):       # 1, 2, 3, 4, 5\n    print(i)\n\nfor i in range(0, 10, 2):   # 0, 2, 4, 6, 8\n    print(i)\n\n# Loop with index\nfor i, name in enumerate(names):\n    print(f\"{i}: {name}\")\n\n# Loop over dictionary\nfor key, value in person.items():\n    print(f\"{key}: {value}\")\n\n# List comprehension (faster and more Pythonic)\nsquares = [x**2 for x in range(1, 6)]\nfiltered = [x for x in numbers if x &gt; 10]\n</code></pre>"},{"location":"guides/python_basics_for_analysts/#while-loops","title":"While Loops","text":"<pre><code>count = 0\nwhile count &lt; 5:\n    print(count)\n    count += 1\n\n# Break and continue\nfor i in range(10):\n    if i == 3:\n        continue  # Skip this iteration\n    if i == 7:\n        break     # Exit loop\n    print(i)\n</code></pre>"},{"location":"guides/python_basics_for_analysts/#functions","title":"Functions","text":""},{"location":"guides/python_basics_for_analysts/#defining-functions","title":"Defining Functions","text":"<pre><code>def greet(name):\n    \"\"\"Print a greeting message.\"\"\"\n    print(f\"Hello, {name}!\")\n\ngreet(\"Alice\")  # Call the function\n\n# Return values\ndef add(a, b):\n    \"\"\"Return the sum of a and b.\"\"\"\n    return a + b\n\nresult = add(5, 3)  # 8\n\n# Multiple return values\ndef min_max(numbers):\n    \"\"\"Return min and max of numbers.\"\"\"\n    return min(numbers), max(numbers)\n\nminimum, maximum = min_max([1, 2, 3, 4, 5])\n\n# Default parameters\ndef greet(name, greeting=\"Hello\"):\n    return f\"{greeting}, {name}!\"\n\ngreet(\"Alice\")              # \"Hello, Alice!\"\ngreet(\"Bob\", \"Hi\")          # \"Hi, Bob!\"\n\n# Keyword arguments\ndef describe(name, age, city):\n    return f\"{name} is {age} years old and lives in {city}\"\n\ndescribe(name=\"Alice\", age=25, city=\"NYC\")  # Can specify in any order\n</code></pre>"},{"location":"guides/python_basics_for_analysts/#lambda-functions","title":"Lambda Functions","text":"<pre><code># Anonymous functions (useful for quick operations)\nsquare = lambda x: x**2\nsquare(5)  # 25\n\n# Often used with map, filter\nnumbers = [1, 2, 3, 4, 5]\nsquared = list(map(lambda x: x**2, numbers))\nevens = list(filter(lambda x: x % 2 == 0, numbers))\n\n# But list comprehensions are often clearer\nsquared = [x**2 for x in numbers]\nevens = [x for x in numbers if x % 2 == 0]\n</code></pre>"},{"location":"guides/python_basics_for_analysts/#working-with-files","title":"Working with Files","text":""},{"location":"guides/python_basics_for_analysts/#reading-files","title":"Reading Files","text":"<pre><code># Read entire file\nwith open('data.txt', 'r') as file:\n    content = file.read()\n\n# Read line by line\nwith open('data.txt', 'r') as file:\n    for line in file:\n        print(line.strip())  # Remove newline\n\n# Read into list\nwith open('data.txt', 'r') as file:\n    lines = file.readlines()  # List of lines\n\n# For CSV, use pandas!\nimport pandas as pd\ndf = pd.read_csv('data.csv')\n</code></pre>"},{"location":"guides/python_basics_for_analysts/#writing-files","title":"Writing Files","text":"<pre><code># Write to file (overwrites)\nwith open('output.txt', 'w') as file:\n    file.write(\"Hello, world!\\n\")\n    file.write(\"Second line\\n\")\n\n# Append to file\nwith open('output.txt', 'a') as file:\n    file.write(\"Appended line\\n\")\n\n# For CSV, use pandas!\ndf.to_csv('output.csv', index=False)\n</code></pre>"},{"location":"guides/python_basics_for_analysts/#error-handling","title":"Error Handling","text":"<pre><code># Try-except blocks\ntry:\n    result = 10 / 0\nexcept ZeroDivisionError:\n    print(\"Cannot divide by zero!\")\n\n# Multiple exceptions\ntry:\n    value = int(input(\"Enter a number: \"))\n    result = 10 / value\nexcept ValueError:\n    print(\"That's not a number!\")\nexcept ZeroDivisionError:\n    print(\"Cannot divide by zero!\")\n\n# Catch all (use sparingly)\ntry:\n    # risky operation\n    pass\nexcept Exception as e:\n    print(f\"Error: {e}\")\n\n# Finally block (always runs)\ntry:\n    file = open('data.txt')\n    # process file\nfinally:\n    file.close()\n</code></pre>"},{"location":"guides/python_basics_for_analysts/#importing-modules","title":"Importing Modules","text":""},{"location":"guides/python_basics_for_analysts/#standard-library","title":"Standard Library","text":"<pre><code># Import entire module\nimport math\nmath.sqrt(16)  # 4.0\nmath.pi        # 3.141592653589793\n\n# Import specific items\nfrom math import sqrt, pi\nsqrt(16)  # No need for math.\npi\n\n# Import with alias\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n</code></pre>"},{"location":"guides/python_basics_for_analysts/#organizing-code","title":"Organizing Code","text":"<pre><code># my_functions.py\ndef calculate_total(prices):\n    return sum(prices)\n\n# main.py\nfrom my_functions import calculate_total\ntotal = calculate_total([10, 20, 30])\n</code></pre>"},{"location":"guides/python_basics_for_analysts/#python-for-r-users","title":"Python for R Users","text":"Concept R Python (pandas) Data frame <code>df</code> <code>df</code> Select column <code>df$column</code> or <code>df['column']</code> <code>df['column']</code> Filter rows <code>df[df$age &gt; 25, ]</code> <code>df[df['age'] &gt; 25]</code> New column <code>df$new &lt;- df$a + df$b</code> <code>df['new'] = df['a'] + df['b']</code> Group by <code>aggregate()</code> or <code>dplyr::group_by()</code> <code>df.groupby().agg()</code> Summary <code>summary(df)</code> <code>df.describe()</code> Missing values <code>is.na(df)</code> <code>df.isnull()</code> Join <code>merge(df1, df2)</code> <code>pd.merge(df1, df2)</code>"},{"location":"guides/python_basics_for_analysts/#python-for-spss-users","title":"Python for SPSS Users","text":"Task SPSS Python (pandas) Import data File \u2192 Open \u2192 Data <code>pd.read_csv()</code> or <code>pd.read_spss()</code> View data Data View <code>df.head()</code>, <code>df.info()</code> Frequencies Analyze \u2192 Descriptive \u2192 Frequencies <code>df['col'].value_counts()</code> Descriptives Analyze \u2192 Descriptive \u2192 Descriptives <code>df.describe()</code> Filter Data \u2192 Select Cases <code>df[df['age'] &gt; 25]</code> Compute Transform \u2192 Compute Variable <code>df['new'] = df['a'] + df['b']</code> Recode Transform \u2192 Recode <code>df['col'].replace()</code> or <code>df['col'].map()</code> Cross-tabs Analyze \u2192 Descriptive \u2192 Crosstabs <code>pd.crosstab()</code> T-test Analyze \u2192 Compare Means \u2192 T-Test <code>scipy.stats.ttest_ind()</code>"},{"location":"guides/python_basics_for_analysts/#best-practices","title":"Best Practices","text":""},{"location":"guides/python_basics_for_analysts/#code-style","title":"Code Style","text":"<pre><code># Use meaningful variable names\ncustomer_age = 25  # Good\nx = 25             # Bad\n\n# Use snake_case for variables and functions\ndef calculate_total_price():\n    pass\n\n# Use UPPER_CASE for constants\nMAX_RETRIES = 3\nDEFAULT_TIMEOUT = 30\n\n# Add docstrings to functions\ndef calculate_mean(values):\n    \"\"\"\n    Calculate the mean of a list of values.\n\n    Parameters:\n    values (list): List of numeric values\n\n    Returns:\n    float: The mean value\n    \"\"\"\n    return sum(values) / len(values)\n</code></pre>"},{"location":"guides/python_basics_for_analysts/#common-pitfalls-for-beginners","title":"Common Pitfalls for Beginners","text":"<pre><code># 1. Mutable default arguments (don't do this!)\ndef add_item(item, items=[]):  # BAD!\n    items.append(item)\n    return items\n\n# Do this instead:\ndef add_item(item, items=None):\n    if items is None:\n        items = []\n    items.append(item)\n    return items\n\n# 2. Integer division in Python 2 (not an issue in Python 3)\n# Python 3: 5 / 2 = 2.5\n# Python 2: 5 / 2 = 2 (use 5.0 / 2)\n\n# 3. Modifying a list while iterating\n# Don't do this:\nfor item in items:\n    if condition:\n        items.remove(item)  # BAD!\n\n# Do this instead:\nitems = [item for item in items if not condition]\n\n# 4. Using == to compare to None\n# Don't: if x == None:\n# Do: if x is None:\n</code></pre>"},{"location":"guides/python_basics_for_analysts/#next-steps","title":"Next Steps","text":"<p>Now that you know the basics:</p> <ol> <li>Practice with data: Try the Quick Start Guide</li> <li>Learn pandas: See the pandas Overview</li> <li>Explore notebooks: Work through <code>notebooks/01_into_and_data_loading.ipynb</code></li> <li>Cheat sheets: Bookmark the Cheat Sheets</li> </ol>"},{"location":"guides/python_basics_for_analysts/#recommended-learning-resources","title":"Recommended Learning Resources","text":"<ul> <li>Official Python Tutorial: docs.python.org/tutorial</li> <li>Real Python: realpython.com</li> <li>Python for Data Analysis by Wes McKinney (pandas creator)</li> <li>Automate the Boring Stuff with Python: automatetheboringstuff.com</li> </ul>"},{"location":"guides/r-to-python/","title":"R to Python Guide","text":"<p>Welcome R users! This guide will help you leverage your R knowledge to quickly become productive in Python.</p>"},{"location":"guides/r-to-python/#core-dplyr-to-pandas-quick-reference","title":"Core dplyr to pandas Quick Reference","text":"<p>The table below shows the most common R dplyr operations and their pandas equivalents. These are the operations you'll use daily.</p>"},{"location":"guides/r-to-python/#select-columns","title":"Select Columns","text":"Operation R (dplyr) Python (pandas) Select specific columns <code>df %&gt;% select(name, age)</code> <code>df[['name', 'age']]</code> Select by condition <code>df %&gt;% select(starts_with(\"sal\"))</code> <code>df.filter(like='sal')</code> Drop columns <code>df %&gt;% select(-age)</code> <code>df.drop(columns=['age'])</code> <p>Pandas Example:</p> <pre><code>import pandas as pd\n\n# Sample data\ndf = pd.DataFrame({\n    'name': ['Alice', 'Bob', 'Charlie'],\n    'age': [25, 30, 35],\n    'salary': [50000, 60000, 55000],\n    'dept': ['Sales', 'IT', 'Sales']\n})\n\n# Select specific columns\nresult = df[['name', 'age']]\n</code></pre>"},{"location":"guides/r-to-python/#filter-rows","title":"Filter Rows","text":"Operation R (dplyr) Python (pandas) Simple filter <code>df %&gt;% filter(age &gt; 25)</code> <code>df[df['age'] &gt; 25]</code> Multiple conditions (AND) <code>df %&gt;% filter(age &gt; 25 &amp; dept == \"Sales\")</code> <code>df[(df['age'] &gt; 25) &amp; (df['dept'] == 'Sales')]</code> Multiple conditions (OR) <code>df %&gt;% filter(age &gt; 25 \\| dept == \"Sales\")</code> <code>df[(df['age'] &gt; 25) \\| (df['dept'] == 'Sales')]</code> Using query (cleaner) N/A <code>df.query('age &gt; 25 &amp; dept == \"Sales\"')</code> <p>Pandas Example:</p> <pre><code># Filter rows where age &gt; 25\nresult = df[df['age'] &gt; 25]\n\n# Multiple conditions - need parentheses and &amp; instead of 'and'\nresult = df[(df['age'] &gt; 25) &amp; (df['dept'] == 'Sales')]\n\n# Using query method (more readable)\nresult = df.query('age &gt; 25 &amp; dept == \"Sales\"')\n</code></pre>"},{"location":"guides/r-to-python/#createmodify-columns-mutate","title":"Create/Modify Columns (Mutate)","text":"Operation R (dplyr) Python (pandas) Create new column <code>df %&gt;% mutate(bonus = salary * 0.1)</code> <code>df['bonus'] = df['salary'] * 0.1</code> Multiple columns <code>df %&gt;% mutate(bonus = salary * 0.1, total = salary + bonus)</code> <code>df.assign(bonus=df['salary'] * 0.1).assign(total=lambda x: x['salary'] + x['bonus'])</code> Conditional column <code>df %&gt;% mutate(senior = if_else(age &gt; 30, \"Yes\", \"No\"))</code> <code>df['senior'] = df['age'].apply(lambda x: 'Yes' if x &gt; 30 else 'No')</code> or <code>np.where(df['age'] &gt; 30, 'Yes', 'No')</code> <p>Pandas Example:</p> <pre><code>import numpy as np\n\n# Create new column\ndf['bonus'] = df['salary'] * 0.1\n\n# Create multiple columns\ndf['bonus'] = df['salary'] * 0.1\ndf['total_comp'] = df['salary'] + df['bonus']\n\n# Method chaining with assign\ndf = df.assign(\n    bonus=lambda x: x['salary'] * 0.1,\n    total_comp=lambda x: x['salary'] + x['bonus']\n)\n\n# Conditional column\ndf['senior'] = np.where(df['age'] &gt; 30, 'Yes', 'No')\n# Or using apply\ndf['senior'] = df['age'].apply(lambda x: 'Yes' if x &gt; 30 else 'No')\n</code></pre>"},{"location":"guides/r-to-python/#group-by-and-summarise","title":"Group By and Summarise","text":"Operation R (dplyr) Python (pandas) Single aggregation <code>df %&gt;% group_by(dept) %&gt;% summarise(avg_sal = mean(salary))</code> <code>df.groupby('dept')['salary'].mean()</code> Multiple aggregations <code>df %&gt;% group_by(dept) %&gt;% summarise(avg_sal = mean(salary), count = n())</code> <code>df.groupby('dept')['salary'].agg(['mean', 'count'])</code> Multiple columns <code>df %&gt;% group_by(dept) %&gt;% summarise(avg_sal = mean(salary), avg_age = mean(age))</code> <code>df.groupby('dept').agg({'salary': 'mean', 'age': 'mean'})</code> Multiple groups <code>df %&gt;% group_by(dept, senior) %&gt;% summarise(avg_sal = mean(salary))</code> <code>df.groupby(['dept', 'senior'])['salary'].mean()</code> <p>Pandas Example:</p> <pre><code># Single aggregation\nresult = df.groupby('dept')['salary'].mean()\n\n# Multiple aggregations on same column\nresult = df.groupby('dept')['salary'].agg(['mean', 'count', 'min', 'max'])\n\n# Multiple aggregations on different columns\nresult = df.groupby('dept').agg({\n    'salary': ['mean', 'sum'],\n    'age': ['mean', 'min', 'max']\n})\n\n# Multiple grouping variables\nresult = df.groupby(['dept', 'senior'])['salary'].mean()\n\n# With custom names (pandas 0.25+)\nresult = df.groupby('dept').agg(\n    avg_salary=('salary', 'mean'),\n    count=('salary', 'size'),\n    max_age=('age', 'max')\n)\n</code></pre>"},{"location":"guides/r-to-python/#joinmerge-dataframes","title":"Join/Merge DataFrames","text":"Operation R (dplyr) Python (pandas) Left join <code>left_join(df1, df2, by = \"id\")</code> <code>pd.merge(df1, df2, on='id', how='left')</code> Inner join <code>inner_join(df1, df2, by = \"id\")</code> <code>pd.merge(df1, df2, on='id', how='inner')</code> Full outer join <code>full_join(df1, df2, by = \"id\")</code> <code>pd.merge(df1, df2, on='id', how='outer')</code> Join on different columns <code>left_join(df1, df2, by = c(\"id1\" = \"id2\"))</code> <code>pd.merge(df1, df2, left_on='id1', right_on='id2', how='left')</code> <p>Pandas Example:</p> <pre><code># Sample data for joins\ndf1 = pd.DataFrame({\n    'id': [1, 2, 3],\n    'name': ['Alice', 'Bob', 'Charlie']\n})\n\ndf2 = pd.DataFrame({\n    'id': [1, 2, 4],\n    'salary': [50000, 60000, 55000]\n})\n\n# Left join - keep all rows from df1\nresult = pd.merge(df1, df2, on='id', how='left')\n\n# Inner join - only matching rows\nresult = pd.merge(df1, df2, on='id', how='inner')\n\n# Outer join - all rows from both\nresult = pd.merge(df1, df2, on='id', how='outer')\n\n# Join on different column names\nresult = pd.merge(df1, df2, left_on='id', right_on='employee_id', how='left')\n</code></pre>"},{"location":"guides/r-to-python/#philosophy-differences","title":"Philosophy Differences","text":"Aspect R Python Primary Focus Statistical computing General-purpose programming Data Structure Data frames (built-in) Data frames (via pandas) Indexing 1-based 0-based Assignment <code>&lt;-</code> or <code>=</code> <code>=</code> Packages CRAN, install.packages() PyPI, pip install"},{"location":"guides/r-to-python/#additional-operations","title":"Additional Operations","text":""},{"location":"guides/r-to-python/#installation-setup","title":"Installation &amp; Setup","text":"<p>R</p> <pre><code>install.packages(\"dplyr\")\nlibrary(dplyr)\n</code></pre> <p>Python</p> <pre><code># Install (in terminal)\npip install pandas\n\n# Import\nimport pandas as pd\n</code></pre>"},{"location":"guides/r-to-python/#reading-data","title":"Reading Data","text":"<p>R</p> <pre><code># CSV\ndf &lt;- read.csv(\"data.csv\")\n\n# Excel\nlibrary(readxl)\ndf &lt;- read_excel(\"data.xlsx\")\n</code></pre> <p>Python</p> <pre><code># CSV\ndf = pd.read_csv(\"data.csv\")\n\n# Excel\ndf = pd.read_excel(\"data.xlsx\")\n\n# Using local data files\ndf = pd.read_csv(\"data/socio_demos.csv\")\n</code></pre>"},{"location":"guides/r-to-python/#data-inspection","title":"Data Inspection","text":"R Python <code>head(df)</code> <code>df.head()</code> <code>tail(df)</code> <code>df.tail()</code> <code>str(df)</code> <code>df.info()</code> <code>summary(df)</code> <code>df.describe()</code> <code>dim(df)</code> <code>df.shape</code> <code>names(df)</code> <code>df.columns</code>"},{"location":"guides/r-to-python/#sorting","title":"Sorting","text":"<p>R</p> <pre><code># dplyr\ndf %&gt;% arrange(age)\ndf %&gt;% arrange(desc(age))\n</code></pre> <p>Python</p> <pre><code># pandas\ndf.sort_values('age')\ndf.sort_values('age', ascending=False)\n\n# Multiple columns\ndf.sort_values(['dept', 'age'], ascending=[True, False])\n</code></pre>"},{"location":"guides/r-to-python/#reshaping-data","title":"Reshaping Data","text":"<p>R</p> <pre><code># Wide to long\nlibrary(tidyr)\ndf_long &lt;- df %&gt;% pivot_longer(cols = c(Q1, Q2, Q3))\n\n# Long to wide\ndf_wide &lt;- df %&gt;% pivot_wider(names_from = quarter, values_from = revenue)\n</code></pre> <p>Python</p> <pre><code># Wide to long\ndf_long = pd.melt(df, id_vars=['id'], value_vars=['Q1', 'Q2', 'Q3'])\n\n# Long to wide\ndf_wide = df.pivot(index='id', columns='quarter', values='revenue')\n</code></pre>"},{"location":"guides/r-to-python/#missing-data","title":"Missing Data","text":"<p>R</p> <pre><code># Check for NA\nis.na(df$column)\n\n# Remove rows with NA\ndf %&gt;% drop_na()\n\n# Fill NA\ndf %&gt;% replace_na(list(column = 0))\n</code></pre> <p>Python</p> <pre><code># Check for NaN\ndf['column'].isna()\n\n# Remove rows with NaN\ndf.dropna()\n\n# Fill NaN\ndf.fillna(0)\ndf['column'].fillna(0)\n</code></pre>"},{"location":"guides/r-to-python/#the-pipe-operator-method-chaining","title":"The Pipe Operator / Method Chaining","text":"<p>R (tidyverse)</p> <pre><code>df %&gt;%\n  filter(age &gt; 25) %&gt;%\n  group_by(department) %&gt;%\n  summarize(avg_salary = mean(salary)) %&gt;%\n  arrange(desc(avg_salary))\n</code></pre> <p>Python (method chaining)</p> <pre><code>(df\n .query('age &gt; 25')\n .groupby('department')['salary']\n .mean()\n .sort_values(ascending=False)\n)\n</code></pre>"},{"location":"guides/r-to-python/#visualization","title":"Visualization","text":"<p>R (ggplot2)</p> <pre><code>library(ggplot2)\n\nggplot(df, aes(x = age, y = salary)) +\n  geom_point() +\n  labs(title = \"Salary vs Age\")\n</code></pre> <p>Python (seaborn - most ggplot2-like)</p> <pre><code>import matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.scatterplot(data=df, x='age', y='salary')\nplt.title('Salary vs Age')\nplt.show()\n</code></pre>"},{"location":"guides/r-to-python/#statistical-tests","title":"Statistical Tests","text":"<p>R</p> <pre><code># t-test\nt.test(group1, group2)\n\n# Linear regression\nmodel &lt;- lm(y ~ x1 + x2, data = df)\nsummary(model)\n</code></pre> <p>Python</p> <pre><code>from scipy import stats\nimport statsmodels.formula.api as smf\n\n# t-test\nstats.ttest_ind(group1, group2)\n\n# Linear regression\nmodel = smf.ols('y ~ x1 + x2', data=df).fit()\nprint(model.summary())\n</code></pre>"},{"location":"guides/r-to-python/#pro-tips-for-r-users","title":"Pro Tips for R Users","text":"<p>Embrace 0-based indexing</p> <p>Remember: Python uses 0-based indexing. The first element is at position 0.</p> <p>Use parentheses for conditions</p> <p>When filtering with multiple conditions, wrap each in parentheses: <code>(df['a'] &gt; 5) &amp; (df['b'] &lt; 10)</code></p> <p>Think in methods</p> <p>Python/pandas uses methods: <code>df.method()</code> instead of R's <code>function(df)</code></p> <p>Try method chaining</p> <p>Like R's pipe (<code>%&gt;%</code>), Python allows chaining: <code>df.filter().groupby().mean()</code></p> <p>Watch out for copies vs views</p> <p>In pandas, some operations return views, others return copies. Use <code>.copy()</code> when unsure.</p>"},{"location":"guides/r-to-python/#next-steps","title":"Next Steps","text":"<ul> <li>Try the Python Basics Tutorial</li> <li>Work through the notebooks in the <code>notebooks/</code> directory</li> <li>Experiment with the data files in <code>data/</code> directory</li> <li>Check out pandas documentation</li> <li>Explore the cheat sheets</li> </ul> <p>You'll find that many concepts translate directly. Python just has different syntax for the same ideas you already know!</p>"},{"location":"guides/spss-to-python/","title":"SPSS to Python Guide","text":"<p>Welcome SPSS users! This guide will help you translate your SPSS knowledge into Python for data analysis.</p>"},{"location":"guides/spss-to-python/#why-transition-from-spss-to-python","title":"Why Transition from SPSS to Python?","text":"<ul> <li>Cost: Python is free and open-source</li> <li>Flexibility: Full programming language, not just statistical procedures</li> <li>Integration: Easily connect to databases, APIs, and web services</li> <li>Reproducibility: Code-based analysis is easier to document and share</li> <li>Community: Large, active community with extensive packages</li> </ul>"},{"location":"guides/spss-to-python/#core-spss-to-python-quick-reference","title":"Core SPSS to Python Quick Reference","text":""},{"location":"guides/spss-to-python/#data-management","title":"Data Management","text":"Operation SPSS Python (pandas) Read CSV <code>GET DATA /TYPE=TXT /FILE=\"data.csv\"</code> <code>df = pd.read_csv(\"data.csv\")</code> Read SPSS file Open in SPSS <code>df = pd.read_spss(\"data.sav\")</code> or <code>df, meta = pyreadstat.read_sav(\"data.sav\")</code> View data Data View <code>df.head()</code> or open in VS Code Select cases <code>SELECT IF (age &gt; 25)</code> <code>df = df[df['age'] &gt; 25]</code> Compute variable <code>COMPUTE total = var1 + var2</code> <code>df['total'] = df['var1'] + df['var2']</code> Recode variable <code>RECODE age (18 thru 30=1) (31 thru 50=2)</code> <code>df['age_group'] = pd.cut(df['age'], bins=[18, 30, 50, 100], labels=[1, 2, 3])</code> Sort cases <code>SORT CASES BY age (D)</code> <code>df = df.sort_values('age', ascending=False)</code> <p>Pandas Example:</p> <pre><code>import pandas as pd\n\n# Read data (using provided sample data)\ndf = pd.read_csv(\"data/socio_demos.csv\")\n\n# View first few rows\nprint(df.head())\n\n# Select cases (filter)\nadults = df[df['age'] &gt; 18]\n\n# Compute new variable\ndf['age_squared'] = df['age'] ** 2\n\n# Sort by age descending\ndf = df.sort_values('age', ascending=False)\n</code></pre>"},{"location":"guides/spss-to-python/#descriptive-statistics","title":"Descriptive Statistics","text":"Procedure SPSS Python (pandas) Frequencies <code>FREQUENCIES VARIABLES=gender</code> <code>df['gender'].value_counts()</code> Descriptives <code>DESCRIPTIVES VARIABLES=age salary</code> <code>df[['age', 'salary']].describe()</code> Crosstabs <code>CROSSTABS /TABLES=dept BY gender</code> <code>pd.crosstab(df['dept'], df['gender'])</code> Means by group <code>MEANS TABLES=salary BY department</code> <code>df.groupby('department')['salary'].mean()</code> <p>Pandas Example:</p> <pre><code># Frequencies\nprint(df['Gender'].value_counts())\nprint(df['Gender'].value_counts(normalize=True) * 100)  # Percentages\n\n# Descriptive statistics\nprint(df[['Number_of_children', 'People_in_Household']].describe())\n\n# Crosstabs\ncrosstab = pd.crosstab(df['Gender'], df['People_in_Household'])\nprint(crosstab)\n\n# Mean by group\nprint(df.groupby('Gender')['weight'].mean())\n</code></pre>"},{"location":"guides/spss-to-python/#statistical-tests","title":"Statistical Tests","text":"Test SPSS Python (scipy/statsmodels) t-test <code>T-TEST GROUPS=gender(0 1) /VARIABLES=salary</code> <code>stats.ttest_ind(group1, group2)</code> Chi-square <code>CROSSTABS ... /STATISTICS=CHISQ</code> <code>chi2, p, dof, expected = chi2_contingency(crosstab)</code> Correlation <code>CORRELATIONS /VARIABLES=age salary</code> <code>df[['age', 'salary']].corr()</code> ANOVA <code>ONEWAY salary BY department</code> <code>stats.f_oneway(group1, group2, group3)</code> Regression <code>REGRESSION /DEPENDENT=salary /METHOD=ENTER age experience</code> <code>model = smf.ols('salary ~ age + experience', data=df).fit()</code> <p>Pandas Example:</p> <pre><code>from scipy import stats\nimport statsmodels.formula.api as smf\n\n# Independent t-test\nmale = df[df['Gender'] == 'male']['weight']\nfemale = df[df['Gender'] == 'female']['weight']\nt_stat, p_value = stats.ttest_ind(male, female)\nprint(f\"t-statistic: {t_stat:.3f}, p-value: {p_value:.3f}\")\n\n# Chi-square test\ncrosstab = pd.crosstab(df['Gender'], df['People_in_Household'])\nchi2, p_value, dof, expected = stats.chi2_contingency(crosstab)\nprint(f\"Chi-square: {chi2:.3f}, p-value: {p_value:.3f}\")\n\n# Correlation\ncorr_matrix = df[['age', 'weight']].corr()\nprint(corr_matrix)\n</code></pre>"},{"location":"guides/spss-to-python/#data-aggregation","title":"Data Aggregation","text":"Operation SPSS Python (pandas) Aggregate simple <code>AGGREGATE /BREAK=dept /mean_sal=MEAN(salary)</code> <code>df.groupby('dept')['salary'].mean()</code> Aggregate multiple <code>AGGREGATE /BREAK=dept /mean_sal=MEAN(salary) /count=N</code> <code>df.groupby('dept')['salary'].agg(['mean', 'count'])</code> Add aggregated variable <code>AGGREGATE /OUTFILE=* MODE=ADDVARIABLES</code> <code>df['dept_mean'] = df.groupby('dept')['salary'].transform('mean')</code> <p>Pandas Example:</p> <pre><code># Simple aggregation\ndept_avg = df.groupby('People_in_Household')['weight'].mean()\nprint(dept_avg)\n\n# Multiple aggregations\ndept_stats = df.groupby('Gender')['weight'].agg(['mean', 'std', 'count'])\nprint(dept_stats)\n\n# Add aggregated variable to original dataframe\ndf['gender_avg_weight'] = df.groupby('Gender')['weight'].transform('mean')\n</code></pre>"},{"location":"guides/spss-to-python/#joiningmerging-data","title":"Joining/Merging Data","text":"Operation SPSS Python (pandas) Match files <code>MATCH FILES /FILE=* /TABLE='file2.sav' /BY id</code> <code>pd.merge(df1, df2, on='id', how='left')</code> Add cases <code>ADD FILES /FILE='file1.sav' /FILE='file2.sav'</code> <code>pd.concat([df1, df2], ignore_index=True)</code> <p>Pandas Example:</p> <pre><code># Read the two sample data files\nsocio = pd.read_csv(\"data/socio_demos.csv\")\nmedia = pd.read_csv(\"data/media_contacts.csv\")\n\n# Merge on person ID (left join - keep all from socio)\n# Note: Column names might differ, so specify left_on and right_on\nmerged = pd.merge(socio, media, \n                  left_on='Person ID', \n                  right_on='PERSON ID', \n                  how='left')\nprint(merged.head())\n</code></pre>"},{"location":"guides/spss-to-python/#reading-spss-files-in-python","title":"Reading SPSS Files in Python","text":"<p>Python can read SPSS <code>.sav</code> files directly!</p>"},{"location":"guides/spss-to-python/#using-pyreadstat-recommended","title":"Using pyreadstat (Recommended)","text":"<pre><code>import pandas as pd\nimport pyreadstat\n\n# Read SPSS file with metadata\ndf, meta = pyreadstat.read_sav('data.sav')\n\n# View data\nprint(df.head())\n\n# View metadata (variable labels, value labels, etc.)\nprint(meta.column_names_to_labels)\nprint(meta.variable_value_labels)\n\n# Access variable labels\nlabels = meta.column_names_to_labels\nprint(labels)\n\n# Write back with labels preserved\npyreadstat.write_sav(df, 'output.sav',\n                     column_labels=labels,\n                     variable_value_labels=meta.variable_value_labels)\n</code></pre>"},{"location":"guides/spss-to-python/#using-pandas","title":"Using pandas","text":"<pre><code>import pandas as pd\n\n# Read SPSS file (newer versions)\ndf = pd.read_spss('data.sav')\n</code></pre>"},{"location":"guides/spss-to-python/#common-spss-procedures-in-detail","title":"Common SPSS Procedures in Detail","text":""},{"location":"guides/spss-to-python/#frequencies","title":"FREQUENCIES","text":"<p>SPSS:</p> <pre><code>FREQUENCIES VARIABLES=gender department\n  /ORDER=ANALYSIS.\n</code></pre> <p>Python:</p> <pre><code># Single variable\nprint(df['gender'].value_counts())\n\n# Multiple variables\nfor col in ['gender', 'department']:\n    print(f\"\\nFrequencies for {col}:\")\n    print(df[col].value_counts())\n\n# With percentages\nprint(df['gender'].value_counts(normalize=True) * 100)\n</code></pre>"},{"location":"guides/spss-to-python/#crosstabs-with-chi-square","title":"CROSSTABS with Chi-Square","text":"<p>SPSS:</p> <pre><code>CROSSTABS\n  /TABLES=department BY gender\n  /STATISTICS=CHISQ.\n</code></pre> <p>Python:</p> <pre><code>from scipy.stats import chi2_contingency\n\n# Create crosstab\ncrosstab = pd.crosstab(df['department'], df['gender'])\nprint(crosstab)\n\n# Chi-square test\nchi2, p_value, dof, expected = chi2_contingency(crosstab)\nprint(f\"Chi-square: {chi2:.3f}\")\nprint(f\"p-value: {p_value:.3f}\")\nprint(f\"Degrees of freedom: {dof}\")\n</code></pre>"},{"location":"guides/spss-to-python/#t-test","title":"T-TEST","text":"<p>SPSS:</p> <pre><code>T-TEST GROUPS=gender(0 1)\n  /VARIABLES=salary.\n</code></pre> <p>Python:</p> <pre><code>from scipy import stats\n\n# Split groups\ngroup1 = df[df['gender'] == 0]['salary']\ngroup2 = df[df['gender'] == 1]['salary']\n\n# Independent t-test\nt_stat, p_value = stats.ttest_ind(group1, group2)\nprint(f\"t-statistic: {t_stat:.3f}\")\nprint(f\"p-value: {p_value:.3f}\")\n\n# With equal_var=False for Welch's t-test\nt_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)\n</code></pre>"},{"location":"guides/spss-to-python/#oneway-anova-with-post-hoc","title":"ONEWAY ANOVA with Post-hoc","text":"<p>SPSS:</p> <pre><code>ONEWAY salary BY department\n  /STATISTICS=DESCRIPTIVES\n  /POSTHOC=TUKEY.\n</code></pre> <p>Python:</p> <pre><code>from scipy import stats\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd\n\n# One-way ANOVA\ngroups = [group['salary'].values for name, group in df.groupby('department')]\nf_stat, p_value = stats.f_oneway(*groups)\nprint(f\"F-statistic: {f_stat:.3f}\")\nprint(f\"p-value: {p_value:.3f}\")\n\n# With more detail using statsmodels\nmodel = ols('salary ~ C(department)', data=df).fit()\nanova_table = sm.stats.anova_lm(model, typ=2)\nprint(anova_table)\n\n# Post-hoc Tukey test\ntukey = pairwise_tukeyhsd(endog=df['salary'], groups=df['department'])\nprint(tukey)\n</code></pre>"},{"location":"guides/spss-to-python/#regression","title":"REGRESSION","text":"<p>SPSS:</p> <pre><code>REGRESSION\n  /DEPENDENT salary\n  /METHOD=ENTER age experience education.\n</code></pre> <p>Python:</p> <pre><code>import statsmodels.formula.api as smf\n\n# Linear regression\nmodel = smf.ols('salary ~ age + experience + education', data=df).fit()\nprint(model.summary())\n\n# Get specific statistics\nprint(f\"R-squared: {model.rsquared:.3f}\")\nprint(f\"Adjusted R-squared: {model.rsquared_adj:.3f}\")\nprint(\"\\nCoefficients:\")\nprint(model.params)\nprint(\"\\np-values:\")\nprint(model.pvalues)\n</code></pre>"},{"location":"guides/spss-to-python/#correlation","title":"CORRELATION","text":"<p>SPSS:</p> <pre><code>CORRELATIONS\n  /VARIABLES=age salary experience\n  /PRINT=TWOTAIL NOSIG.\n</code></pre> <p>Python:</p> <pre><code>from scipy.stats import pearsonr\n\n# Pearson correlation matrix\ncorr_matrix = df[['age', 'salary', 'experience']].corr()\nprint(corr_matrix)\n\n# Individual correlation with p-value\nr, p = pearsonr(df['age'], df['salary'])\nprint(f\"Correlation: {r:.3f}\")\nprint(f\"p-value: {p:.3f}\")\n</code></pre>"},{"location":"guides/spss-to-python/#data-transformation-examples","title":"Data Transformation Examples","text":""},{"location":"guides/spss-to-python/#compute","title":"COMPUTE","text":"<p>SPSS:</p> <pre><code>COMPUTE total_comp = salary + bonus.\nCOMPUTE age_squared = age * age.\n</code></pre> <p>Python:</p> <pre><code># Create new variables\ndf['total_comp'] = df['salary'] + df['bonus']\ndf['age_squared'] = df['age'] ** 2\n</code></pre>"},{"location":"guides/spss-to-python/#recode","title":"RECODE","text":"<p>SPSS:</p> <pre><code>RECODE age (18 thru 30=1) (31 thru 50=2) (51 thru 99=3) INTO age_group.\n</code></pre> <p>Python:</p> <pre><code># Using cut\ndf['age_group'] = pd.cut(df['age'], \n                          bins=[0, 30, 50, 100], \n                          labels=[1, 2, 3])\n\n# Or using conditions\nimport numpy as np\nconditions = [\n    (df['age'] &lt;= 30),\n    (df['age'] &lt;= 50),\n    (df['age'] &gt; 50)\n]\ndf['age_group'] = np.select(conditions, [1, 2, 3])\n</code></pre>"},{"location":"guides/spss-to-python/#visualization","title":"Visualization","text":""},{"location":"guides/spss-to-python/#bar-chart","title":"Bar Chart","text":"<p>SPSS:</p> <pre><code>GRAPH\n  /BAR=COUNT BY department.\n</code></pre> <p>Python:</p> <pre><code>import matplotlib.pyplot as plt\n\n# Bar chart\ndf['department'].value_counts().plot(kind='bar')\nplt.title('Count by Department')\nplt.xlabel('Department')\nplt.ylabel('Count')\nplt.show()\n</code></pre>"},{"location":"guides/spss-to-python/#histogram","title":"Histogram","text":"<p>SPSS:</p> <pre><code>GRAPH\n  /HISTOGRAM=salary.\n</code></pre> <p>Python:</p> <pre><code># Histogram\ndf['salary'].hist(bins=20)\nplt.title('Salary Distribution')\nplt.xlabel('Salary')\nplt.ylabel('Frequency')\nplt.show()\n</code></pre>"},{"location":"guides/spss-to-python/#scatterplot","title":"Scatterplot","text":"<p>SPSS:</p> <pre><code>GRAPH\n  /SCATTERPLOT=age WITH salary.\n</code></pre> <p>Python:</p> <pre><code>import seaborn as sns\n\n# Scatter plot with seaborn\nsns.scatterplot(data=df, x='age', y='salary', hue='department')\nplt.title('Salary vs Age')\nplt.show()\n</code></pre>"},{"location":"guides/spss-to-python/#missing-values","title":"Missing Values","text":"<p>SPSS:</p> <pre><code>RECODE age (SYSMIS=99).\nMISSING VALUES age (99).\n</code></pre> <p>Python:</p> <pre><code># Check for missing\nprint(df.isnull().sum())\n\n# Fill missing with a value\ndf['age'].fillna(99, inplace=True)\n\n# Drop rows with missing\ndf_clean = df.dropna()\n\n# Drop columns with any missing\ndf_clean = df.dropna(axis=1)\n</code></pre>"},{"location":"guides/spss-to-python/#exporting-data","title":"Exporting Data","text":""},{"location":"guides/spss-to-python/#export-to-spss","title":"Export to SPSS","text":"<pre><code># Save as SPSS file with metadata\npyreadstat.write_sav(df, 'output.sav')\n</code></pre>"},{"location":"guides/spss-to-python/#export-to-excel","title":"Export to Excel","text":"<pre><code># Single sheet\ndf.to_excel('output.xlsx', index=False)\n\n# Multiple sheets\nwith pd.ExcelWriter('output.xlsx') as writer:\n    df.to_excel(writer, sheet_name='Data', index=False)\n    summary.to_excel(writer, sheet_name='Summary', index=False)\n</code></pre>"},{"location":"guides/spss-to-python/#export-to-csv","title":"Export to CSV","text":"<pre><code>df.to_csv('output.csv', index=False)\n</code></pre>"},{"location":"guides/spss-to-python/#pro-tips-for-spss-users","title":"Pro Tips for SPSS Users","text":"<p>Think in DataFrames</p> <p>In Python, everything is a DataFrame object. Operations are methods: <code>df.method()</code></p> <p>Use VS Code with Jupyter</p> <p>VS Code + Jupyter extension provides an experience similar to SPSS syntax editor but interactive</p> <p>Leverage Libraries</p> <ul> <li>pandas: Data manipulation (like SPSS data view/variable view)</li> <li>scipy: Statistical tests</li> <li>statsmodels: Regression and advanced statistics</li> <li>matplotlib/seaborn: Graphics</li> </ul> <p>0-based Indexing</p> <p>Python uses 0-based indexing. The first row/column is at position 0.</p> <p>Automation</p> <p>Python excels at automation. One script can process multiple files, generate reports, etc.</p>"},{"location":"guides/spss-to-python/#next-steps","title":"Next Steps","text":"<ul> <li>Work through the Quick Start Guide</li> <li>Try the notebooks in the <code>notebooks/</code> directory</li> <li>Practice with the sample data files in <code>data/</code></li> <li>Explore the Statistical Analysis Tutorial</li> <li>Check the Cheat Sheets</li> </ul> <p>The transition from SPSS to Python opens up powerful new possibilities for your analysis!</p>"},{"location":"guides/pandas/cheat_sheet/","title":"pandas Cheat Sheet","text":"<p>Quick reference for common pandas operations.</p> <p>See Also</p> <p>For complete examples with real data, check out the notebooks folder, starting with 01_into_and_data_loading.ipynb.</p>"},{"location":"guides/pandas/cheat_sheet/#import","title":"Import","text":"<pre><code>import pandas as pd\nimport numpy as np\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#reading-data","title":"Reading Data","text":"<pre><code>pd.read_csv('file.csv')\npd.read_csv('file.csv', sep=';', encoding='utf-8')\npd.read_excel('file.xlsx', sheet_name='Sheet1')\npd.read_json('file.json')\npd.read_sql('SELECT * FROM table', conn)\npd.read_clipboard()  # From clipboard\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#viewing-data","title":"Viewing Data","text":"<pre><code>df.head()           # First 5 rows\ndf.head(10)         # First 10 rows\ndf.tail()           # Last 5 rows\ndf.shape            # (rows, columns)\ndf.columns          # Column names\ndf.dtypes           # Data types\ndf.info()           # Overview\ndf.describe()       # Statistics (numeric)\ndf.describe(include='all')  # All columns\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#selecting-data","title":"Selecting Data","text":""},{"location":"guides/pandas/cheat_sheet/#columns","title":"Columns","text":"<pre><code>df['column']                    # Single column (Series)\ndf[['col1', 'col2']]           # Multiple columns (DataFrame)\ndf.drop('col', axis=1)          # Drop column\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#rows","title":"Rows","text":"<pre><code>df.iloc[0]                      # First row by position\ndf.iloc[0:5]                    # First 5 rows\ndf.iloc[[0, 2, 4]]             # Specific rows by position\ndf.loc[0]                       # Row by index label\ndf.loc[0:5]                     # Slice by label (inclusive)\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#conditional","title":"Conditional","text":"<pre><code>df[df['age'] &gt; 25]                          # Filter rows\ndf[(df['age'] &gt; 25) &amp; (df['city'] == 'NYC')]  # Multiple conditions\ndf[df['city'].isin(['NYC', 'LA'])]          # Multiple values\ndf.query('age &gt; 25 and city == \"NYC\"')      # Query string\ndf.loc[df['age'] &gt; 25, ['name', 'age']]     # Specific columns\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#creating-columns","title":"Creating Columns","text":"<pre><code>df['new'] = df['a'] + df['b']               # From calculation\ndf['category'] = df['age'].apply(lambda x: 'Adult' if x &gt;= 18 else 'Minor')\ndf['status'] = np.where(df['age'] &gt; 30, 'Senior', 'Junior')\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#removing-data","title":"Removing Data","text":"<pre><code>df.drop('col', axis=1, inplace=True)        # Drop column\ndf.drop([0, 1], inplace=True)               # Drop rows by index\ndf.dropna()                                  # Drop rows with missing\ndf.dropna(subset=['col'])                   # Drop if specific column missing\ndf.drop_duplicates()                        # Drop duplicate rows\ndf.drop_duplicates(subset=['col'])          # Based on specific column\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#sorting","title":"Sorting","text":"<pre><code>df.sort_values('col')                       # Sort by column\ndf.sort_values('col', ascending=False)      # Descending\ndf.sort_values(['col1', 'col2'])           # Multiple columns\ndf.sort_index()                             # Sort by index\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#grouping-and-aggregating","title":"Grouping and Aggregating","text":"<pre><code>df.groupby('col').mean()                    # Group and aggregate\ndf.groupby('col')['value'].mean()          # Specific column\ndf.groupby('col').agg(['mean', 'sum'])     # Multiple aggregations\ndf.groupby('col').agg({                     # Different aggs per column\n    'val1': 'mean',\n    'val2': ['sum', 'count']\n})\ndf.groupby(['col1', 'col2']).mean()        # Multiple grouping columns\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#merging-and-joining","title":"Merging and Joining","text":"<pre><code>pd.merge(df1, df2, on='key')                       # Inner join\npd.merge(df1, df2, on='key', how='left')          # Left join\npd.merge(df1, df2, on='key', how='outer')         # Outer join\npd.merge(df1, df2, left_on='k1', right_on='k2')   # Different key names\npd.concat([df1, df2])                              # Append rows\npd.concat([df1, df2], axis=1)                      # Append columns\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#missing-data","title":"Missing Data","text":"<pre><code>df.isnull()                                 # Check for missing\ndf.isnull().sum()                          # Count missing per column\ndf.dropna()                                 # Drop rows with any missing\ndf.dropna(how='all')                       # Drop only if all missing\ndf.fillna(0)                               # Fill with value\ndf.fillna({'col1': 0, 'col2': 'Unknown'})  # Different values per column\ndf['col'].fillna(df['col'].mean())         # Fill with mean\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#data-types","title":"Data Types","text":"<pre><code>df.dtypes                                   # Check types\ndf['col'].astype(int)                      # Convert type\ndf['col'].astype('category')               # To categorical\npd.to_datetime(df['col'])                  # To datetime\npd.to_numeric(df['col'], errors='coerce')  # To numeric (invalid \u2192 NaN)\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#string-operations","title":"String Operations","text":"<pre><code>df['col'].str.lower()                      # Lowercase\ndf['col'].str.upper()                      # Uppercase\ndf['col'].str.strip()                      # Remove whitespace\ndf['col'].str.replace('old', 'new')        # Replace\ndf['col'].str.contains('pattern')          # Contains\ndf['col'].str.split(',')                   # Split\ndf['col'].str[0:5]                         # Slice\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#value-counts-and-unique","title":"Value Counts and Unique","text":"<pre><code>df['col'].unique()                         # Unique values\ndf['col'].nunique()                        # Count unique\ndf['col'].value_counts()                   # Frequency count\ndf['col'].value_counts(normalize=True)     # Proportions\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#reshaping","title":"Reshaping","text":"<pre><code># Pivot table\ndf.pivot_table(\n    values='sales',\n    index='month',\n    columns='region',\n    aggfunc='sum'\n)\n\n# Wide to long\npd.melt(df, id_vars=['id'], value_vars=['Q1', 'Q2'])\n\n# Long to wide\ndf.pivot(index='id', columns='quarter', values='sales')\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#apply-and-map","title":"Apply and Map","text":"<pre><code>df['col'].apply(lambda x: x * 2)           # Apply function to Series\ndf.apply(lambda row: row['a'] + row['b'], axis=1)  # Apply to rows\ndf['col'].map({'old': 'new'})              # Map values\ndf.applymap(lambda x: x * 2)               # Apply to all elements (deprecated, use df.map())\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#datetime-operations","title":"Datetime Operations","text":"<pre><code>pd.to_datetime(df['col'])                  # Convert to datetime\ndf['year'] = df['date'].dt.year            # Extract year\ndf['month'] = df['date'].dt.month          # Extract month\ndf['day'] = df['date'].dt.day              # Extract day\ndf['dayofweek'] = df['date'].dt.dayofweek  # Day of week (0=Monday)\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#writing-data","title":"Writing Data","text":"<pre><code>df.to_csv('file.csv', index=False)\ndf.to_csv('file.csv', index=False, encoding='utf-8')\ndf.to_excel('file.xlsx', sheet_name='Sheet1', index=False)\ndf.to_json('file.json', orient='records')\ndf.to_sql('table', conn, if_exists='replace', index=False)\ndf.to_clipboard(index=False)               # Copy to clipboard\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#common-patterns","title":"Common Patterns","text":""},{"location":"guides/pandas/cheat_sheet/#rename-columns","title":"Rename Columns","text":"<pre><code>df.rename(columns={'old': 'new'}, inplace=True)\ndf.columns = ['new1', 'new2', 'new3']\ndf.columns = df.columns.str.lower()        # Make lowercase\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#replace-values","title":"Replace Values","text":"<pre><code>df['col'].replace('old', 'new')\ndf['col'].replace(['old1', 'old2'], ['new1', 'new2'])\ndf['col'].replace({'old1': 'new1', 'old2': 'new2'})\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#filter-and-select","title":"Filter and Select","text":"<pre><code># Select specific columns for specific rows\ndf.loc[df['age'] &gt; 25, ['name', 'age']]\n\n# Top N rows\ndf.nlargest(10, 'salary')\ndf.nsmallest(10, 'age')\n\n# Sample random rows\ndf.sample(10)\ndf.sample(frac=0.1)  # 10% of rows\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#copy-to-avoid-warnings","title":"Copy to Avoid Warnings","text":"<pre><code>df_subset = df[df['age'] &gt; 25].copy()\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#method-chaining","title":"Method Chaining","text":"<pre><code>result = (df\n    .query('age &gt; 25')\n    .groupby('city')['salary']\n    .mean()\n    .reset_index()\n    .sort_values('salary', ascending=False)\n)\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#comparison-with-other-tools","title":"Comparison with Other Tools","text":""},{"location":"guides/pandas/cheat_sheet/#r-dplyr","title":"R (dplyr)","text":"R (dplyr) pandas <code>filter()</code> <code>df[df['col'] &gt; 5]</code> or <code>df.query()</code> <code>select()</code> <code>df[['col1', 'col2']]</code> <code>mutate()</code> <code>df['new'] = ...</code> <code>arrange()</code> <code>df.sort_values()</code> <code>group_by() %&gt;% summarize()</code> <code>df.groupby().agg()</code> <code>left_join()</code> <code>pd.merge(..., how='left')</code>"},{"location":"guides/pandas/cheat_sheet/#sql","title":"SQL","text":"SQL pandas <code>SELECT col1, col2 FROM table</code> <code>df[['col1', 'col2']]</code> <code>WHERE age &gt; 25</code> <code>df[df['age'] &gt; 25]</code> <code>ORDER BY col</code> <code>df.sort_values('col')</code> <code>GROUP BY col</code> <code>df.groupby('col')</code> <code>COUNT(*)</code> <code>df.groupby('col').size()</code> <code>LEFT JOIN</code> <code>pd.merge(..., how='left')</code>"},{"location":"guides/pandas/cheat_sheet/#performance-tips","title":"Performance Tips","text":"<ol> <li>Use vectorized operations instead of loops</li> <li>Use <code>.loc</code> or <code>.iloc</code> for selection (not chained indexing)</li> <li>Specify <code>dtype</code> when reading data to save memory</li> <li>Use <code>category</code> dtype for low-cardinality strings</li> <li>Use <code>query()</code> for complex filters (can be faster)</li> <li>Read large files in chunks with <code>chunksize</code></li> </ol> <pre><code># Good (vectorized)\ndf['total'] = df['price'] * df['quantity']\n\n# Bad (loop)\nfor i in range(len(df)):\n    df.loc[i, 'total'] = df.loc[i, 'price'] * df.loc[i, 'quantity']\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#common-errors-and-solutions","title":"Common Errors and Solutions","text":""},{"location":"guides/pandas/cheat_sheet/#settingwithcopywarning","title":"SettingWithCopyWarning","text":"<pre><code># Problem\ndf_subset = df[df['age'] &gt; 25]\ndf_subset['new_col'] = 1  # Warning!\n\n# Solution\ndf_subset = df[df['age'] &gt; 25].copy()\ndf_subset['new_col'] = 1  # OK\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#keyerror-column_name","title":"KeyError: 'column_name'","text":"<pre><code># Check if column exists\n'column_name' in df.columns\n\n# List all columns\ndf.columns.tolist()\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#valueerror-length-mismatch","title":"ValueError: Length mismatch","text":"<pre><code># When assigning a new column, length must match\nlen(df) == len(new_values)  # Must be True\n</code></pre>"},{"location":"guides/pandas/cheat_sheet/#resources","title":"Resources","text":"<ul> <li>Official docs: pandas.pydata.org/docs</li> <li>10 Minutes to pandas: Quick tutorial</li> <li>Cheat Sheet PDF: Download</li> <li>User Guide: Comprehensive guide</li> </ul>"},{"location":"guides/pandas/overview/","title":"pandas Overview","text":"<p>pandas is the essential Python library for data manipulation and analysis. This guide provides a comprehensive introduction for analysts.</p> <p>Hands-On Practice</p> <p>For interactive examples using real datasets, see notebooks/01_into_and_data_loading.ipynb and subsequent notebooks.</p>"},{"location":"guides/pandas/overview/#what-is-pandas","title":"What is pandas?","text":"<p>pandas is built on NumPy and provides:</p> <ul> <li>DataFrame: 2D labeled data structure (like a spreadsheet or SQL table)</li> <li>Series: 1D labeled array (like a single column)</li> <li>Powerful data manipulation: filter, group, merge, reshape</li> <li>Time series functionality: date ranges, resampling, rolling windows</li> <li>I/O tools: read/write CSV, Excel, SQL, JSON, and more</li> </ul>"},{"location":"guides/pandas/overview/#core-concepts","title":"Core Concepts","text":""},{"location":"guides/pandas/overview/#dataframe","title":"DataFrame","text":"<p>The primary pandas data structure - a 2D table with labeled rows and columns.</p> <pre><code>import pandas as pd\n\n# Create from dictionary\ndata = {\n    'name': ['Alice', 'Bob', 'Charlie'],\n    'age': [25, 30, 35],\n    'city': ['NYC', 'LA', 'Chicago']\n}\ndf = pd.DataFrame(data)\n</code></pre>"},{"location":"guides/pandas/overview/#series","title":"Series","text":"<p>A single column of data with an index.</p> <pre><code># Extract a column (returns a Series)\nages = df['age']\n\n# Create a Series directly\ns = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n</code></pre>"},{"location":"guides/pandas/overview/#index","title":"Index","text":"<p>Row labels that enable fast lookups and alignment.</p> <pre><code># Default integer index\ndf.index  # RangeIndex(start=0, stop=3, step=1)\n\n# Set a column as index\ndf.set_index('name', inplace=True)\n\n# Reset to default integer index\ndf.reset_index(inplace=True)\n</code></pre>"},{"location":"guides/pandas/overview/#reading-data","title":"Reading Data","text":""},{"location":"guides/pandas/overview/#from-csv","title":"From CSV","text":"<pre><code># Basic read\ndf = pd.read_csv('file.csv')\n\n# With options\ndf = pd.read_csv(\n    'file.csv',\n    sep=',',                 # Delimiter\n    encoding='utf-8',        # Encoding\n    na_values=['NA', ''],    # Treat as missing\n    parse_dates=['date'],    # Parse dates\n    skiprows=1,              # Skip first row\n    nrows=1000               # Read only first 1000 rows\n)\n</code></pre>"},{"location":"guides/pandas/overview/#from-excel","title":"From Excel","text":"<pre><code># Single sheet\ndf = pd.read_excel('file.xlsx', sheet_name='Sheet1')\n\n# Multiple sheets\nsheets = pd.read_excel('file.xlsx', sheet_name=None)  # Returns dict\n\n# Specific range\ndf = pd.read_excel('file.xlsx', usecols='A:D', nrows=100)\n</code></pre>"},{"location":"guides/pandas/overview/#from-other-sources","title":"From Other Sources","text":"<pre><code># JSON\ndf = pd.read_json('file.json')\n\n# SQL database\nimport sqlite3\nconn = sqlite3.connect('database.db')\ndf = pd.read_sql('SELECT * FROM table', conn)\n\n# SPSS (requires pyreadstat)\nimport pyreadstat\ndf, meta = pyreadstat.read_sav('file.sav')\n\n# Clipboard\ndf = pd.read_clipboard()  # Paste from Excel!\n</code></pre>"},{"location":"guides/pandas/overview/#inspecting-data","title":"Inspecting Data","text":""},{"location":"guides/pandas/overview/#quick-overview","title":"Quick Overview","text":"<pre><code># First/last rows\ndf.head()      # First 5 rows\ndf.head(10)    # First 10 rows\ndf.tail()      # Last 5 rows\n\n# Shape and size\ndf.shape       # (rows, columns)\ndf.size        # Total elements\nlen(df)        # Number of rows\n\n# Column info\ndf.columns     # Column names\ndf.dtypes      # Data types\ndf.info()      # Comprehensive summary\n\n# Statistics\ndf.describe()                    # Numeric columns\ndf.describe(include='all')       # All columns\ndf.describe(include=['object'])  # Only text columns\n</code></pre>"},{"location":"guides/pandas/overview/#data-types","title":"Data Types","text":"<pre><code># Check types\ndf.dtypes\n\n# Convert types\ndf['age'] = df['age'].astype(int)\ndf['price'] = df['price'].astype(float)\ndf['date'] = pd.to_datetime(df['date'])\ndf['category'] = df['category'].astype('category')\n\n# Infer better types\ndf = df.infer_objects()\n</code></pre>"},{"location":"guides/pandas/overview/#missing-data","title":"Missing Data","text":"<pre><code># Detect missing\ndf.isnull()         # Boolean DataFrame\ndf.isnull().sum()   # Count per column\ndf.isnull().sum().sum()  # Total missing\n\n# Detect non-missing\ndf.notnull()\n\n# Check for any missing in each column\ndf.isnull().any()\n</code></pre>"},{"location":"guides/pandas/overview/#selecting-data","title":"Selecting Data","text":""},{"location":"guides/pandas/overview/#by-column","title":"By Column","text":"<pre><code># Single column (returns Series)\ndf['name']\ndf.name  # Alternative (if name is valid Python identifier)\n\n# Multiple columns (returns DataFrame)\ndf[['name', 'age']]\n\n# All columns except some\ndf.drop(['col1', 'col2'], axis=1)\n</code></pre>"},{"location":"guides/pandas/overview/#by-row-position-iloc","title":"By Row Position (.iloc)","text":"<pre><code># Single row\ndf.iloc[0]       # First row\ndf.iloc[-1]      # Last row\n\n# Multiple rows\ndf.iloc[0:5]     # First 5 rows\ndf.iloc[[0, 2, 4]]  # Specific rows\n\n# Rows and columns\ndf.iloc[0:5, 0:3]    # First 5 rows, first 3 columns\ndf.iloc[:, [0, 2]]   # All rows, columns 0 and 2\n</code></pre>"},{"location":"guides/pandas/overview/#by-label-loc","title":"By Label (.loc)","text":"<pre><code># Single row by index label\ndf.loc[0]\ndf.loc['row_name']\n\n# Multiple rows\ndf.loc[0:5]                # Inclusive end\ndf.loc[['name1', 'name2']]\n\n# Rows and columns\ndf.loc[:, 'age']              # All rows, one column\ndf.loc[:, ['name', 'age']]    # All rows, multiple columns\ndf.loc[0:5, 'age':'city']     # Row and column slices\n</code></pre>"},{"location":"guides/pandas/overview/#boolean-indexing","title":"Boolean Indexing","text":"<pre><code># Single condition\ndf[df['age'] &gt; 30]\n\n# Multiple conditions (use &amp; and |, with parentheses)\ndf[(df['age'] &gt; 25) &amp; (df['city'] == 'NYC')]\ndf[(df['age'] &lt; 25) | (df['age'] &gt; 40)]\n\n# Not condition\ndf[~(df['age'] &gt; 30)]\n\n# isin for multiple values\ndf[df['city'].isin(['NYC', 'LA'])]\n\n# String contains\ndf[df['name'].str.contains('Ali')]\n\n# Combine loc with boolean\ndf.loc[df['age'] &gt; 30, ['name', 'age']]\n</code></pre>"},{"location":"guides/pandas/overview/#query-method","title":"Query Method","text":"<pre><code># Alternative to boolean indexing\ndf.query('age &gt; 30')\ndf.query('age &gt; 30 and city == \"NYC\"')\ndf.query('age &gt; @threshold')  # Use variable with @\n</code></pre>"},{"location":"guides/pandas/overview/#modifying-data","title":"Modifying Data","text":""},{"location":"guides/pandas/overview/#adding-columns","title":"Adding Columns","text":"<pre><code># New column from calculation\ndf['age_squared'] = df['age'] ** 2\n\n# Conditional column\ndf['category'] = df['age'].apply(lambda x: 'Adult' if x &gt;= 18 else 'Minor')\n\n# Using np.where\nimport numpy as np\ndf['status'] = np.where(df['age'] &gt; 30, 'Senior', 'Junior')\n\n# Insert at specific position\ndf.insert(1, 'new_col', [1, 2, 3])\n</code></pre>"},{"location":"guides/pandas/overview/#removing-columns","title":"Removing Columns","text":"<pre><code># Drop columns\ndf.drop('column_name', axis=1, inplace=True)\ndf.drop(['col1', 'col2'], axis=1, inplace=True)\n\n# Alternative\ndf = df.drop('column_name', axis=1)\n</code></pre>"},{"location":"guides/pandas/overview/#removing-rows","title":"Removing Rows","text":"<pre><code># Drop by index\ndf.drop(0, inplace=True)\ndf.drop([0, 1, 2], inplace=True)\n\n# Drop by condition\ndf = df[df['age'] &gt; 0]\n\n# Drop duplicates\ndf.drop_duplicates(inplace=True)\ndf.drop_duplicates(subset=['name'], inplace=True)\n\n# Drop rows with missing values\ndf.dropna(inplace=True)                      # Any missing\ndf.dropna(subset=['col1', 'col2'], inplace=True)  # Specific columns\n</code></pre>"},{"location":"guides/pandas/overview/#renaming","title":"Renaming","text":"<pre><code># Rename columns\ndf.rename(columns={'old_name': 'new_name'}, inplace=True)\ndf.rename(columns={'age': 'years', 'name': 'full_name'}, inplace=True)\n\n# Set column names directly\ndf.columns = ['new1', 'new2', 'new3']\n\n# Make columns lowercase\ndf.columns = df.columns.str.lower()\n</code></pre>"},{"location":"guides/pandas/overview/#sorting-and-ranking","title":"Sorting and Ranking","text":""},{"location":"guides/pandas/overview/#sort-by-values","title":"Sort by Values","text":"<pre><code># Sort by one column\ndf.sort_values('age')\ndf.sort_values('age', ascending=False)\n\n# Sort by multiple columns\ndf.sort_values(['city', 'age'])\ndf.sort_values(['city', 'age'], ascending=[True, False])\n\n# In place\ndf.sort_values('age', inplace=True)\n</code></pre>"},{"location":"guides/pandas/overview/#sort-by-index","title":"Sort by Index","text":"<pre><code>df.sort_index()\ndf.sort_index(ascending=False)\n</code></pre>"},{"location":"guides/pandas/overview/#ranking","title":"Ranking","text":"<pre><code>df['rank'] = df['age'].rank()\ndf['rank'] = df['age'].rank(method='dense', ascending=False)\n</code></pre>"},{"location":"guides/pandas/overview/#grouping-and-aggregating","title":"Grouping and Aggregating","text":""},{"location":"guides/pandas/overview/#basic-grouping","title":"Basic Grouping","text":"<pre><code># Single aggregation\ndf.groupby('city')['age'].mean()\n\n# Multiple aggregations on same column\ndf.groupby('city')['age'].agg(['mean', 'min', 'max'])\n\n# Different aggregations on different columns\ndf.groupby('city').agg({\n    'age': ['mean', 'min', 'max'],\n    'salary': 'sum'\n})\n\n# Group by multiple columns\ndf.groupby(['city', 'department'])['salary'].mean()\n</code></pre>"},{"location":"guides/pandas/overview/#common-aggregations","title":"Common Aggregations","text":"<pre><code># Available aggregation functions\ngrouped = df.groupby('city')\ngrouped.count()     # Count non-null values\ngrouped.sum()       # Sum\ngrouped.mean()      # Mean\ngrouped.median()    # Median\ngrouped.min()       # Minimum\ngrouped.max()       # Maximum\ngrouped.std()       # Standard deviation\ngrouped.var()       # Variance\ngrouped.first()     # First value\ngrouped.last()      # Last value\ngrouped.size()      # Count including nulls\n</code></pre>"},{"location":"guides/pandas/overview/#transform-and-apply","title":"Transform and Apply","text":"<pre><code># Transform: same shape as input\ndf['age_mean_by_city'] = df.groupby('city')['age'].transform('mean')\n\n# Apply: custom function\ndf.groupby('city')['age'].apply(lambda x: x.max() - x.min())\n</code></pre>"},{"location":"guides/pandas/overview/#merging-and-joining","title":"Merging and Joining","text":""},{"location":"guides/pandas/overview/#merge-sql-style-joins","title":"Merge (SQL-style joins)","text":"<pre><code># Inner join (default)\npd.merge(df1, df2, on='key')\n\n# Left join\npd.merge(df1, df2, on='key', how='left')\n\n# Right join\npd.merge(df1, df2, on='key', how='right')\n\n# Outer join\npd.merge(df1, df2, on='key', how='outer')\n\n# Different column names\npd.merge(df1, df2, left_on='key1', right_on='key2')\n\n# Multiple keys\npd.merge(df1, df2, on=['key1', 'key2'])\n</code></pre>"},{"location":"guides/pandas/overview/#concatenate","title":"Concatenate","text":"<pre><code># Vertically (stack rows)\npd.concat([df1, df2])\npd.concat([df1, df2], ignore_index=True)\n\n# Horizontally (add columns)\npd.concat([df1, df2], axis=1)\n</code></pre>"},{"location":"guides/pandas/overview/#join","title":"Join","text":"<pre><code># Join on index\ndf1.join(df2)\ndf1.join(df2, how='left')\n</code></pre>"},{"location":"guides/pandas/overview/#handling-missing-data","title":"Handling Missing Data","text":""},{"location":"guides/pandas/overview/#detect-missing","title":"Detect Missing","text":"<pre><code>df.isnull()\ndf.notnull()\ndf.isnull().sum()\n</code></pre>"},{"location":"guides/pandas/overview/#remove-missing","title":"Remove Missing","text":"<pre><code># Drop any rows with missing\ndf.dropna()\n\n# Drop only if all values are missing\ndf.dropna(how='all')\n\n# Drop based on specific columns\ndf.dropna(subset=['col1', 'col2'])\n</code></pre>"},{"location":"guides/pandas/overview/#fill-missing","title":"Fill Missing","text":"<pre><code># Fill with specific value\ndf.fillna(0)\ndf.fillna({'col1': 0, 'col2': 'Unknown'})\n\n# Forward fill\ndf.fillna(method='ffill')\n\n# Backward fill\ndf.fillna(method='bfill')\n\n# Fill with mean\ndf['age'].fillna(df['age'].mean(), inplace=True)\n\n# Interpolate\ndf['value'].interpolate(inplace=True)\n</code></pre>"},{"location":"guides/pandas/overview/#writing-data","title":"Writing Data","text":""},{"location":"guides/pandas/overview/#to-csv","title":"To CSV","text":"<pre><code>df.to_csv('output.csv', index=False)\ndf.to_csv('output.csv', index=False, encoding='utf-8')\ndf.to_csv('output.csv', columns=['col1', 'col2'])  # Specific columns\n</code></pre>"},{"location":"guides/pandas/overview/#to-excel","title":"To Excel","text":"<pre><code>df.to_excel('output.xlsx', sheet_name='Sheet1', index=False)\n\n# Multiple sheets\nwith pd.ExcelWriter('output.xlsx') as writer:\n    df1.to_excel(writer, sheet_name='Sheet1', index=False)\n    df2.to_excel(writer, sheet_name='Sheet2', index=False)\n</code></pre>"},{"location":"guides/pandas/overview/#to-other-formats","title":"To Other Formats","text":"<pre><code># JSON\ndf.to_json('output.json', orient='records')\n\n# SQL\ndf.to_sql('table_name', conn, if_exists='replace', index=False)\n\n# Clipboard (for pasting into Excel)\ndf.to_clipboard(index=False)\n</code></pre>"},{"location":"guides/pandas/overview/#best-practices","title":"Best Practices","text":""},{"location":"guides/pandas/overview/#method-chaining","title":"Method Chaining","text":"<pre><code># Instead of multiple statements\ndf = df[df['age'] &gt; 25]\ndf = df.sort_values('age')\ndf = df.reset_index(drop=True)\n\n# Use chaining\ndf = (df[df['age'] &gt; 25]\n      .sort_values('age')\n      .reset_index(drop=True))\n</code></pre>"},{"location":"guides/pandas/overview/#copy-vs-view","title":"Copy vs View","text":"<pre><code># Create a copy to avoid SettingWithCopyWarning\ndf_subset = df[df['age'] &gt; 25].copy()\n\n# Now safe to modify\ndf_subset['new_col'] = 1\n</code></pre>"},{"location":"guides/pandas/overview/#performance-tips","title":"Performance Tips","text":"<ol> <li>Use vectorized operations instead of loops</li> <li>Use categorical dtype for low-cardinality string columns</li> <li>Read only needed columns: <code>usecols</code> parameter</li> <li>Use chunks for large files: <code>chunksize</code> parameter</li> <li>Specify dtypes when reading to save memory</li> </ol> <pre><code># Good: vectorized\ndf['total'] = df['price'] * df['quantity']\n\n# Avoid: loops\nfor i in range(len(df)):\n    df.loc[i, 'total'] = df.loc[i, 'price'] * df.loc[i, 'quantity']\n</code></pre>"},{"location":"guides/pandas/overview/#common-patterns","title":"Common Patterns","text":""},{"location":"guides/pandas/overview/#value-counts","title":"Value Counts","text":"<pre><code># Frequency count\ndf['city'].value_counts()\ndf['city'].value_counts(normalize=True)  # Proportions\n</code></pre>"},{"location":"guides/pandas/overview/#pivot-tables","title":"Pivot Tables","text":"<pre><code># Spreadsheet-style pivot\ndf.pivot_table(\n    values='salary',\n    index='department',\n    columns='city',\n    aggfunc='mean'\n)\n</code></pre>"},{"location":"guides/pandas/overview/#reshaping","title":"Reshaping","text":"<pre><code># Wide to long\npd.melt(df, id_vars=['id'], value_vars=['Q1', 'Q2', 'Q3'])\n\n# Long to wide\ndf.pivot(index='id', columns='quarter', values='sales')\n</code></pre>"},{"location":"guides/pandas/overview/#next-steps","title":"Next Steps","text":"<ul> <li>Practice: Try the notebooks in <code>notebooks/</code></li> <li>Cheat sheet: See the pandas Cheat Sheet</li> <li>Official docs: pandas.pydata.org</li> <li>10 Minutes to pandas: Quick tutorial</li> </ul>"},{"location":"reference/glossary/","title":"Glossary","text":""},{"location":"reference/glossary/#a","title":"A","text":"<p>Array: A NumPy data structure for homogeneous data. The foundation for pandas Series and DataFrame.</p> <p>Axis: Dimension in a DataFrame. <code>axis=0</code> refers to rows (down), <code>axis=1</code> refers to columns (across).</p>"},{"location":"reference/glossary/#b","title":"B","text":"<p>Boolean Indexing: Filtering data using True/False conditions, e.g., <code>df[df['age'] &gt; 25]</code>.</p> <p>Broadcasting: NumPy's method of performing operations on arrays of different shapes.</p>"},{"location":"reference/glossary/#c","title":"C","text":"<p>Column: Vertical dimension in a DataFrame, representing a variable or feature.</p> <p>Crosstab: Cross-tabulation showing frequency distribution of variables (like a contingency table).</p>"},{"location":"reference/glossary/#d","title":"D","text":"<p>DataFrame: pandas' primary 2-dimensional labeled data structure with columns of potentially different types.</p> <p>Dependency Group: Optional dependencies in <code>pyproject.toml</code> for specific use cases (e.g., <code>[dev]</code>, <code>[docs]</code>).</p> <p>dtype: Data type of a column (int64, float64, object, etc.).</p>"},{"location":"reference/glossary/#f","title":"F","text":"<p>Function: Reusable block of code that performs a specific task.</p> <p>f-string: Formatted string literal in Python, e.g., <code>f\"Hello {name}\"</code>.</p>"},{"location":"reference/glossary/#g","title":"G","text":"<p>GroupBy: Operation that splits data, applies a function, and combines results.</p>"},{"location":"reference/glossary/#i","title":"I","text":"<p>iloc: Integer-location based indexing in pandas (position-based).</p> <p>Index: Row labels in a DataFrame or Series.</p> <p>Indexing: Accessing specific elements, rows, or columns in a data structure.</p>"},{"location":"reference/glossary/#j","title":"J","text":"<p>Join: Combining DataFrames based on common columns or indices.</p> <p>Jupyter Notebook: Interactive computational environment for creating notebook documents.</p>"},{"location":"reference/glossary/#l","title":"L","text":"<p>Lambda Function: Anonymous function defined with <code>lambda</code> keyword, e.g., <code>lambda x: x * 2</code>.</p> <p>List: Ordered, mutable collection of items in Python.</p> <p>List Comprehension: Concise way to create lists, e.g., <code>[x**2 for x in range(10)]</code>.</p> <p>loc: Label-based indexing in pandas (label-based).</p>"},{"location":"reference/glossary/#m","title":"M","text":"<p>Merge: Combining DataFrames similar to SQL joins.</p> <p>Method: Function that belongs to an object, called with dot notation, e.g., <code>df.head()</code>.</p> <p>Method Chaining: Calling multiple methods in sequence, e.g., <code>df.filter().sort().head()</code>.</p>"},{"location":"reference/glossary/#n","title":"N","text":"<p>NaN: \"Not a Number\", pandas' marker for missing numerical data.</p> <p>None: Python's null value.</p> <p>NumPy: Numerical Python library, the foundation for pandas.</p>"},{"location":"reference/glossary/#p","title":"P","text":"<p>pandas: Python Data Analysis Library, primary tool for data manipulation.</p> <p>PEP 621: Python Enhancement Proposal defining project metadata format in <code>pyproject.toml</code>.</p> <p>Pivot Table: Reshaping tool that summarizes data using aggregation.</p> <p>pyproject.toml: Modern Python project configuration file (dependencies, metadata, tool settings).</p> <p>Python: High-level, general-purpose programming language.</p>"},{"location":"reference/glossary/#r","title":"R","text":"<p>Row: Horizontal dimension in a DataFrame, representing an observation or record.</p>"},{"location":"reference/glossary/#s","title":"S","text":"<p>Series: pandas' 1-dimensional labeled array, can hold any data type.</p> <p>Slice: Extracting a portion of a sequence, e.g., <code>df[1:5]</code>.</p>"},{"location":"reference/glossary/#t","title":"T","text":"<p>Tuple: Ordered, immutable collection of items in Python.</p>"},{"location":"reference/glossary/#u","title":"U","text":"<p>uv: Modern, fast Python package manager written in Rust. Alternative to pip with automatic venv management.</p>"},{"location":"reference/glossary/#v","title":"V","text":"<p>Vectorization: Performing operations on entire arrays without explicit loops (faster).</p> <p>View: Reference to original data (changes affect original). Opposite of copy.</p>"},{"location":"reference/glossary/#comparison-with-other-tools","title":"Comparison with Other Tools","text":""},{"location":"reference/glossary/#pandas-vs-r","title":"pandas vs R","text":"pandas R equivalent DataFrame data.frame Series vector .head() head() .groupby() group_by() .merge() merge() / join()"},{"location":"reference/glossary/#pandas-vs-spss","title":"pandas vs SPSS","text":"pandas SPSS equivalent pd.read_csv() GET DATA .describe() DESCRIPTIVES .value_counts() FREQUENCIES pd.crosstab() CROSSTABS groupby().mean() MEANS"},{"location":"reference/glossary/#python-vs-r-syntax","title":"Python vs R Syntax","text":"Concept Python R Assignment <code>x = 5</code> <code>x &lt;- 5</code> or <code>x = 5</code> Indexing 0-based 1-based Pipe Method chaining <code>%&gt;%</code> Function call <code>function(data)</code> <code>function(data)</code> Method call <code>data.method()</code> N/A (uses functions)"},{"location":"reference/resources/","title":"Additional Resources","text":""},{"location":"reference/resources/#official-documentation","title":"Official Documentation","text":""},{"location":"reference/resources/#python","title":"Python","text":"<ul> <li>Python.org - Official Python website</li> <li>Python Tutorial - Official tutorial</li> <li>Python Standard Library - Built-in modules</li> </ul>"},{"location":"reference/resources/#pandas","title":"pandas","text":"<ul> <li>pandas Documentation - Official docs</li> <li>10 Minutes to pandas - Quick start</li> <li>pandas Cookbook - Recipes</li> </ul>"},{"location":"reference/resources/#numpy","title":"NumPy","text":"<ul> <li>NumPy Documentation - Official docs</li> <li>NumPy for Beginners - Getting started</li> </ul>"},{"location":"reference/resources/#matplotlib","title":"Matplotlib","text":"<ul> <li>Matplotlib Documentation - Official docs</li> <li>Matplotlib Gallery - Example plots</li> </ul>"},{"location":"reference/resources/#seaborn","title":"Seaborn","text":"<ul> <li>Seaborn Documentation - Official docs</li> <li>Seaborn Tutorial - Comprehensive guide</li> <li>Seaborn Gallery - Example plots</li> </ul>"},{"location":"reference/resources/#scipy","title":"SciPy","text":"<ul> <li>SciPy Documentation - Official docs</li> <li>SciPy Stats - Statistical functions</li> </ul>"},{"location":"reference/resources/#statsmodels","title":"statsmodels","text":"<ul> <li>statsmodels Documentation - Official docs</li> <li>statsmodels Examples - Code examples</li> </ul>"},{"location":"reference/resources/#interactive-tutorials","title":"Interactive Tutorials","text":"<ul> <li>DataCamp - Interactive Python courses</li> <li>Kaggle Learn - Free micro-courses</li> <li>Real Python - Tutorials and articles</li> <li>Python for Data Analysis (Book Code) - Companion code</li> </ul>"},{"location":"reference/resources/#books","title":"Books","text":""},{"location":"reference/resources/#for-beginners","title":"For Beginners","text":"<ul> <li>Python Crash Course by Eric Matthes</li> <li>Automate the Boring Stuff with Python by Al Sweigart (free online)</li> <li>Think Python by Allen Downey (free online)</li> </ul>"},{"location":"reference/resources/#for-data-analysis","title":"For Data Analysis","text":"<ul> <li>Python for Data Analysis by Wes McKinney (pandas creator)</li> <li>Python Data Science Handbook by Jake VanderPlas (free online)</li> <li>Pandas in Action by Boris Paskhaver</li> </ul>"},{"location":"reference/resources/#for-statistics","title":"For Statistics","text":"<ul> <li>Think Stats by Allen Downey (free online)</li> <li>Statistical Thinking in Python (DataCamp course)</li> <li>An Introduction to Statistical Learning (with Python examples)</li> </ul>"},{"location":"reference/resources/#video-courses","title":"Video Courses","text":"<ul> <li>Corey Schafer's Python Tutorials - YouTube</li> <li>sentdex's Python Programming - YouTube</li> <li>Python for Data Science and Machine Learning Bootcamp - Udemy</li> <li>Data Analysis with Python - freeCodeCamp</li> </ul>"},{"location":"reference/resources/#communities","title":"Communities","text":"<ul> <li>r/learnpython - Reddit community</li> <li>Stack Overflow - Q&amp;A site</li> <li>Python Discord - Chat community</li> <li>PyData - Community for Python data tools</li> </ul>"},{"location":"reference/resources/#cheat-sheets","title":"Cheat Sheets","text":"<ul> <li>Python Cheat Sheet</li> <li>pandas Cheat Sheet</li> <li>NumPy Cheat Sheet</li> <li>Matplotlib Cheat Sheet</li> <li>Seaborn Cheat Sheet</li> </ul>"},{"location":"reference/resources/#practice-platforms","title":"Practice Platforms","text":"<ul> <li>HackerRank - Coding challenges</li> <li>LeetCode - Algorithm practice</li> <li>Project Euler - Mathematical problems</li> <li>Kaggle - Data science competitions</li> </ul>"},{"location":"reference/resources/#datasets-for-practice","title":"Datasets for Practice","text":"<ul> <li>Kaggle Datasets - Thousands of datasets</li> <li>UCI Machine Learning Repository - Classic datasets</li> <li>data.gov - US government data</li> <li>Google Dataset Search - Search engine for datasets</li> <li>FiveThirtyEight Data - Data behind stories</li> </ul>"},{"location":"reference/resources/#transitioning-from-r","title":"Transitioning from R","text":"<ul> <li>pandas for R Users</li> <li>R vs Python for Data Science</li> <li>Moving from R to Python</li> </ul>"},{"location":"reference/resources/#transitioning-from-spss","title":"Transitioning from SPSS","text":"<ul> <li>SPSS to Python</li> <li>pyreadstat Documentation - Reading SPSS files</li> <li>Replacing SPSS with Python</li> </ul>"},{"location":"reference/resources/#development-tools","title":"Development Tools","text":"<ul> <li>Jupyter - Interactive notebooks</li> <li>JupyterLab - Next-generation Jupyter</li> <li>VS Code - Popular code editor</li> <li>PyCharm - Python IDE</li> <li>Google Colab - Free cloud notebooks</li> </ul>"},{"location":"reference/resources/#package-managers","title":"Package Managers","text":"<ul> <li>uv - Fast Python package and project manager (recommended)</li> <li>pip - Traditional Python package installer</li> <li>conda - Package and environment manager</li> <li>Anaconda - Python distribution for data science</li> </ul>"},{"location":"reference/resources/#modern-python-standards","title":"Modern Python Standards","text":"<ul> <li>PEP 621 - Project metadata in <code>pyproject.toml</code></li> <li>pyproject.toml Guide - Official packaging guide</li> </ul>"},{"location":"reference/resources/#best-practices","title":"Best Practices","text":"<ul> <li>PEP 8 - Python style guide</li> <li>The Hitchhiker's Guide to Python - Best practices</li> <li>Effective Python - 90 ways to write better Python</li> </ul>"},{"location":"reference/resources/#blogs-and-news","title":"Blogs and News","text":"<ul> <li>Towards Data Science - Medium publication</li> <li>Real Python - Tutorials and articles</li> <li>Python Weekly - Newsletter</li> <li>PyCoders Weekly - Newsletter</li> <li>Planet Python - Blog aggregator</li> </ul> <p>Keep Learning!</p> <p>The Python ecosystem is vast and constantly evolving. These resources will help you:</p> <ul> <li>Stay updated with new features and best practices</li> <li>Find answers to specific questions</li> <li>Connect with other Python users</li> <li>Continue improving your skills</li> </ul> <p>Remember: The best way to learn is by doing. Practice regularly, work on real projects, and don't be afraid to make mistakes!</p>"}]}