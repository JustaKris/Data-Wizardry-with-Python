{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23faa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: imports and display options\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.width = 120\n",
    "pd.options.display.max_rows = 20\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(f\"pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d12472",
   "metadata": {},
   "source": [
    "## 1. Load Fresh Raw Data\n",
    "\n",
    "We'll load the original data and perform all cleaning steps:\n",
    "\n",
    "**Note**: You could also load pre-loaded data from notebook 01 (see commented section at end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd0092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "media_df = pd.read_csv('../data/media_contacts.csv')\n",
    "demo_df = pd.read_csv('../data/socio_demos.csv')\n",
    "\n",
    "print(f\"Media: {media_df.shape}\")\n",
    "print(f\"Demo: {demo_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82ac6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick inspection\n",
    "print(\"Media columns:\")\n",
    "print(media_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b497157",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDemo columns:\")\n",
    "print(demo_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad51d4",
   "metadata": {},
   "source": [
    "## 2. Parsing Dates from BIRTHDAY\n",
    "\n",
    "The `BIRTHDAY` column is stored as a float in YYYYMMDD format (e.g., 19971001.0). We need to convert it to datetime.\n",
    "\n",
    "### Understanding the Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72e708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at raw birthday values\n",
    "print(\"Sample BIRTHDAY values:\")\n",
    "print(demo_df['BIRTHDAY'].head(10))\n",
    "print(f\"\\nData type: {demo_df['BIRTHDAY'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14f99ec",
   "metadata": {},
   "source": [
    "### Method 1: Convert to String then Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb10599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert float to string, remove decimal, then parse\n",
    "demo_df['birthday_dt'] = pd.to_datetime(\n",
    "    demo_df['BIRTHDAY'].astype(int).astype(str), \n",
    "    format='%Y%m%d'\n",
    ")\n",
    "\n",
    "print(\"Converted birthdays:\")\n",
    "print(demo_df[['BIRTHDAY', 'birthday_dt']].head(10))\n",
    "print(f\"\\nNew data type: {demo_df['birthday_dt'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ed8cb9",
   "metadata": {},
   "source": [
    "### Extracting Date Components\n",
    "\n",
    "Once we have datetime, we can extract useful information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b768565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year, month, age\n",
    "demo_df['birth_year'] = demo_df['birthday_dt'].dt.year\n",
    "demo_df['birth_month'] = demo_df['birthday_dt'].dt.month\n",
    "\n",
    "# Calculate age (as of 2025)\n",
    "current_year = 2025\n",
    "demo_df['age'] = current_year - demo_df['birth_year']\n",
    "\n",
    "print(\"Age distribution:\")\n",
    "print(demo_df['age'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f558309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results\n",
    "demo_df[['BIRTHDAY', 'birthday_dt', 'birth_year', 'age']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7931f912",
   "metadata": {},
   "source": [
    "## 3. Cleaning \"Number_of children\"\n",
    "\n",
    "This column has inconsistent values. Let's normalize it to a clean integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf31e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect current values\n",
    "print(\"Unique values in Number_of children:\")\n",
    "print(demo_df['Number_of children'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e531d8ae",
   "metadata": {},
   "source": [
    "### Standardizing the Values\n",
    "\n",
    "We need to extract the number and handle inconsistent formatting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b981cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping function\n",
    "def parse_num_children(value):\n",
    "    \"\"\"Extract number of children from inconsistent strings.\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return 0\n",
    "    \n",
    "    # Convert to lowercase string\n",
    "    val_str = str(value).lower().strip()\n",
    "    \n",
    "    # Handle common patterns\n",
    "    if val_str in ['0', 'no children']:\n",
    "        return 0\n",
    "    elif val_str in ['1 child', '1child']:\n",
    "        return 1\n",
    "    elif val_str in ['2 children', '2children']:\n",
    "        return 2\n",
    "    elif val_str in ['3 children', '3children', '3+']:\n",
    "        return 3\n",
    "    \n",
    "    # Try to extract first digit\n",
    "    import re\n",
    "    match = re.search(r'\\d+', val_str)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    \n",
    "    return 0  # Default\n",
    "\n",
    "# Apply the function\n",
    "demo_df['num_children_clean'] = demo_df['Number_of children'].apply(parse_num_children)\n",
    "\n",
    "print(\"\\nCleaned distribution:\")\n",
    "print(demo_df['num_children_clean'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b45b530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original vs cleaned\n",
    "demo_df[['Number_of children', 'num_children_clean']].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5a7437",
   "metadata": {},
   "source": [
    "### Alternative: Using `.replace()` with a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc078f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another approach - direct mapping\n",
    "children_map = {\n",
    "    '0': 0,\n",
    "    '1 child': 1,\n",
    "    '2 Children': 2,\n",
    "    '3 children': 3,\n",
    "    # Add more as needed\n",
    "}\n",
    "\n",
    "demo_df['num_children_v2'] = demo_df['Number_of children'].replace(children_map)\n",
    "# Fill any unmapped values with 0\n",
    "demo_df['num_children_v2'] = demo_df['num_children_v2'].fillna(0).astype(int)\n",
    "\n",
    "print(demo_df['num_children_v2'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70b06aa",
   "metadata": {},
   "source": [
    "## 4. Normalizing \"People_in_Household\"\n",
    "\n",
    "This column has variations like \"1 -HH (female)\", \"1-HH (male)\", \"2-HH\", etc.\n",
    "\n",
    "Let's extract just the household size number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0216eebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect current values\n",
    "print(\"Unique household values:\")\n",
    "print(demo_df['People_in_Household'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40249fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the number at the start\n",
    "demo_df['household_size_clean'] = demo_df['People_in_Household'].str.extract(r'(\\d+)', expand=False).astype(int)\n",
    "\n",
    "print(\"\\nCleaned household sizes:\")\n",
    "print(demo_df['household_size_clean'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f0899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare\n",
    "demo_df[['People_in_Household', 'household_size_clean']].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5fd4fb",
   "metadata": {},
   "source": [
    "### Creating Household Type Categories\n",
    "\n",
    "We can also extract the household type (male/female/general):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7193c401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract household type\n",
    "def get_household_type(value):\n",
    "    \"\"\"Extract household type from string.\"\"\"\n",
    "    val_str = str(value).lower()\n",
    "    if 'female' in val_str:\n",
    "        return 'single_female'\n",
    "    elif 'male' in val_str:\n",
    "        return 'single_male'\n",
    "    else:\n",
    "        return 'multi_person'\n",
    "\n",
    "demo_df['household_type'] = demo_df['People_in_Household'].apply(get_household_type)\n",
    "\n",
    "print(\"\\nHousehold types:\")\n",
    "print(demo_df['household_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dee1c99",
   "metadata": {},
   "source": [
    "## 5. Handling Missing Values\n",
    "\n",
    "Let's check for missing values in our media data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86020d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "print(\"Missing values in media_df:\")\n",
    "print(media_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cc970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage missing\n",
    "missing_pct = (media_df.isnull().sum() / len(media_df)) * 100\n",
    "print(\"\\nPercentage missing:\")\n",
    "print(missing_pct[missing_pct > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77425b0f",
   "metadata": {},
   "source": [
    "### Filling Missing Values\n",
    "\n",
    "Different strategies for different situations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7ba176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For media columns, 0 makes sense (no exposure = 0)\n",
    "media_cols = ['TV_Total', 'FLYERS', 'Print_Total', 'Online_Video', \n",
    "              'Online_Display', 'Online Total', 'TikTok', 'Pinterest']\n",
    "\n",
    "# Fill missing with 0\n",
    "for col in media_cols:\n",
    "    if col in media_df.columns:\n",
    "        media_df[col] = media_df[col].fillna(0)\n",
    "\n",
    "print(\"After filling:\")\n",
    "print(media_df[media_cols].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5f5bad",
   "metadata": {},
   "source": [
    "### Other Fill Strategies\n",
    "\n",
    "```python\n",
    "# Fill with mean\n",
    "df['column'] = df['column'].fillna(df['column'].mean())\n",
    "\n",
    "# Fill with median (better for skewed data)\n",
    "df['column'] = df['column'].fillna(df['column'].median())\n",
    "\n",
    "# Forward fill (carry last value forward)\n",
    "df['column'] = df['column'].fillna(method='ffill')\n",
    "\n",
    "# Backward fill\n",
    "df['column'] = df['column'].fillna(method='bfill')\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# Drop rows with missing in specific columns\n",
    "df_clean = df.dropna(subset=['important_column'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6484ce2c",
   "metadata": {},
   "source": [
    "## 6. String Operations\n",
    "\n",
    "pandas provides powerful string methods through the `.str` accessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e471ec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean gender column\n",
    "print(\"Original Gender values:\")\n",
    "print(demo_df['Gender'].value_counts())\n",
    "\n",
    "# Standardize to lowercase, strip whitespace\n",
    "demo_df['gender_clean'] = demo_df['Gender'].str.lower().str.strip()\n",
    "\n",
    "print(\"\\nCleaned:\")\n",
    "print(demo_df['gender_clean'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d978c21",
   "metadata": {},
   "source": [
    "### Common String Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c8b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of string operations\n",
    "demo_df['gender_upper'] = demo_df['Gender'].str.upper()\n",
    "demo_df['gender_title'] = demo_df['Gender'].str.title()\n",
    "\n",
    "# Check if string contains pattern\n",
    "demo_df['is_female'] = demo_df['gender_clean'] == 'female'\n",
    "\n",
    "# String length\n",
    "demo_df['name_length'] = demo_df['People_in_Household'].str.len()\n",
    "\n",
    "demo_df[['Gender', 'gender_clean', 'gender_upper', 'is_female']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8d36ec",
   "metadata": {},
   "source": [
    "## 7. Using `.assign()` to Create Multiple Columns\n",
    "\n",
    "`.assign()` is great for creating multiple new columns in one operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a8859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiple columns at once\n",
    "demo_enhanced = demo_df.assign(\n",
    "    age_group=lambda x: pd.cut(x['age'], bins=[0, 18, 35, 50, 65, 100], \n",
    "                                labels=['<18', '18-35', '35-50', '50-65', '65+']),\n",
    "    has_children=lambda x: x['num_children_clean'] > 0,\n",
    "    large_household=lambda x: x['household_size_clean'] >= 4\n",
    ")\n",
    "\n",
    "print(\"New columns created:\")\n",
    "print(demo_enhanced[['age', 'age_group', 'num_children_clean', 'has_children', \n",
    "                      'household_size_clean', 'large_household']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cda1be6",
   "metadata": {},
   "source": [
    "## 8. Data Type Conversions\n",
    "\n",
    "### Converting to Categorical\n",
    "\n",
    "For columns with few unique values, `category` dtype saves memory and speeds up operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46c6ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check memory before\n",
    "print(\"Memory usage before:\")\n",
    "print(f\"Gender: {demo_df['Gender'].memory_usage(deep=True) / 1024:.2f} KB\")\n",
    "\n",
    "# Convert to category\n",
    "demo_df['gender_cat'] = demo_df['gender_clean'].astype('category')\n",
    "\n",
    "print(f\"\\nGender (category): {demo_df['gender_cat'].memory_usage(deep=True) / 1024:.2f} KB\")\n",
    "print(f\"Memory saved: {(demo_df['Gender'].memory_usage(deep=True) - demo_df['gender_cat'].memory_usage(deep=True)) / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fce9493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dtypes\n",
    "print(\"\\nOriginal dtype:\", demo_df['Gender'].dtype)\n",
    "print(\"Category dtype:\", demo_df['gender_cat'].dtype)\n",
    "print(\"Categories:\", demo_df['gender_cat'].cat.categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4d75e9",
   "metadata": {},
   "source": [
    "### Other Type Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42917fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Float to integer (must have no NaNs)\n",
    "demo_df['weight_int'] = demo_df['weight'].fillna(0).astype(int)\n",
    "\n",
    "# Integer to float\n",
    "demo_df['age_float'] = demo_df['age'].astype(float)\n",
    "\n",
    "# String to numeric (coerce errors to NaN)\n",
    "# demo_df['numeric_col'] = pd.to_numeric(demo_df['string_col'], errors='coerce')\n",
    "\n",
    "print(\"Type conversions:\")\n",
    "print(demo_df[['weight', 'weight_int', 'age', 'age_float']].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ebbaa3",
   "metadata": {},
   "source": [
    "## 9. Renaming Columns\n",
    "\n",
    "Clean up column names for easier coding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b437b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize media column names\n",
    "media_df.columns = media_df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "print(\"Standardized media columns:\")\n",
    "print(media_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fb244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename specific columns\n",
    "demo_renamed = demo_df.rename(columns={\n",
    "    'Person ID': 'person_id',\n",
    "    'Number_of children': 'num_children_orig',\n",
    "    'People_in_Household': 'household_orig',\n",
    "    'Gender': 'gender_orig'\n",
    "})\n",
    "\n",
    "print(\"\\nRenamed demo columns:\")\n",
    "print(demo_renamed.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8591f6a2",
   "metadata": {},
   "source": [
    "## 10. Building a Cleaning Pipeline\n",
    "\n",
    "Let's combine everything into a reusable function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dea15a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_demographic_data(df):\n",
    "    \"\"\"\n",
    "    Clean demographic data with all transformations.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        Raw demographic data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame\n",
    "        Cleaned demographic data\n",
    "    \"\"\"\n",
    "    # Copy to avoid modifying original\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Rename columns\n",
    "    df_clean = df_clean.rename(columns={\n",
    "        'Person ID': 'person_id',\n",
    "        'Number_of children': 'num_children_orig',\n",
    "        'People_in_Household': 'household_orig'\n",
    "    })\n",
    "    \n",
    "    # Parse birthday\n",
    "    df_clean['birthday_dt'] = pd.to_datetime(\n",
    "        df_clean['BIRTHDAY'].astype(int).astype(str), \n",
    "        format='%Y%m%d'\n",
    "    )\n",
    "    df_clean['age'] = 2025 - df_clean['birthday_dt'].dt.year\n",
    "    \n",
    "    # Clean number of children\n",
    "    def parse_children(val):\n",
    "        if pd.isna(val):\n",
    "            return 0\n",
    "        import re\n",
    "        match = re.search(r'\\d+', str(val))\n",
    "        return int(match.group()) if match else 0\n",
    "    \n",
    "    df_clean['num_children'] = df_clean['num_children_orig'].apply(parse_children)\n",
    "    \n",
    "    # Extract household size\n",
    "    df_clean['household_size'] = df_clean['household_orig'].str.extract(r'(\\d+)')[0].astype(int)\n",
    "    \n",
    "    # Clean gender\n",
    "    df_clean['gender'] = df_clean['Gender'].str.lower().str.strip().astype('category')\n",
    "    \n",
    "    # Create derived columns\n",
    "    df_clean['age_group'] = pd.cut(\n",
    "        df_clean['age'], \n",
    "        bins=[0, 18, 35, 50, 65, 100],\n",
    "        labels=['<18', '18-35', '35-50', '50-65', '65+']\n",
    "    )\n",
    "    df_clean['has_children'] = df_clean['num_children'] > 0\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Test the pipeline\n",
    "demo_clean = clean_demographic_data(demo_df)\n",
    "print(\"Cleaned demographic data:\")\n",
    "print(demo_clean.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8efd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View cleaned data\n",
    "demo_clean[['person_id', 'age', 'gender', 'num_children', \n",
    "            'household_size', 'age_group', 'has_children']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f998c9",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "âœ… Parse dates from various formats using `pd.to_datetime()`  \n",
    "âœ… Extract date components (year, month, age) with `.dt` accessor  \n",
    "âœ… Clean text columns with string operations (`.str.lower()`, `.str.strip()`, `.str.extract()`)  \n",
    "âœ… Normalize inconsistent categorical data  \n",
    "âœ… Handle missing values with different strategies (`.fillna()`, `.dropna()`)  \n",
    "âœ… Create new columns with `.assign()` and lambda functions  \n",
    "âœ… Convert data types with `.astype()` and `pd.to_numeric()`  \n",
    "âœ… Use categorical dtype for memory efficiency  \n",
    "âœ… Build reusable cleaning pipelines with functions  \n",
    "âœ… Rename columns for consistency\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Always inspect data first**: Use `.value_counts()`, `.unique()`, `.dtypes` before cleaning\n",
    "2. **Handle missing values appropriately**: Different strategies for different situations\n",
    "3. **Use categories for repeated strings**: Saves memory and speeds up operations\n",
    "4. **Build reusable functions**: Create cleaning pipelines you can apply consistently\n",
    "5. **Document your transformations**: Comment your code so others understand the logic\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In the next notebook (**04_eda.ipynb** or similar), we'll:\n",
    "- Explore cleaned data with statistics and visualizations\n",
    "- Create summary tables and crosstabs\n",
    "- Generate insights from the data\n",
    "- Build compelling visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ddf2af",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Practice Exercises\n",
    "\n",
    "Try these on your own:\n",
    "\n",
    "1. Create an \"age_decade\" column (e.g., \"20s\", \"30s\", \"40s\")\n",
    "2. Extract the household gender type (single_male, single_female, multi) from `People_in_Household`\n",
    "3. Create a \"high_weight\" boolean column for weight > median weight\n",
    "4. Bin the age column into quartiles (4 equal groups)\n",
    "5. Find and fix any remaining missing values in the media dataset\n",
    "6. Create a \"total_media_exposure\" column summing all media columns\n",
    "7. Convert all media column names to follow `snake_case` convention\n",
    "8. Create age bins that make sense for your analysis\n",
    "\n",
    "### Bonus Challenges\n",
    "\n",
    "9. Write a function to clean the media dataset (similar to the demo cleaning function)\n",
    "10. Create a \"generation\" column (Gen Z, Millennial, Gen X, Boomer) based on birth year\n",
    "11. Detect and handle outliers in the weight column (values > 3 standard deviations from mean)\n",
    "12. Create a \"media_diversity\" score counting how many different media channels each person uses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6b9e10",
   "metadata": {},
   "source": [
    "## Loading/Saving Data Between Notebooks\n",
    "\n",
    "### Load Data from Previous Notebook\n",
    "\n",
    "If you saved data from notebook 02:\n",
    "\n",
    "```python\n",
    "# Uncomment to load previously selected data\n",
    "# media_df = pd.read_csv('../outputs/media_selected.csv')\n",
    "# demo_df = pd.read_csv('../outputs/demo_selected.csv')\n",
    "```\n",
    "\n",
    "### Save Cleaned Data for Next Notebook\n",
    "\n",
    "Save your cleaned datasets:\n",
    "\n",
    "```python\n",
    "# Uncomment to save cleaned data\n",
    "# demo_clean.to_csv('../outputs/demo_cleaned.csv', index=False)\n",
    "# media_df.to_csv('../outputs/media_cleaned.csv', index=False)\n",
    "\n",
    "# Or save in Parquet format (faster, smaller)\n",
    "# demo_clean.to_parquet('../outputs/demo_cleaned.parquet')\n",
    "# media_df.to_parquet('../outputs/media_cleaned.parquet')\n",
    "```\n",
    "\n",
    "**Note**: Create the `../outputs/` directory first if it doesn't exist!\n",
    "\n",
    "```python\n",
    "# Create outputs directory\n",
    "import os\n",
    "os.makedirs('../outputs', exist_ok=True)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
